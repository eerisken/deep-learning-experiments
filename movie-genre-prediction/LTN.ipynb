{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01bcf10c"
      },
      "source": [
        "### 1. Data Loading and Preprocessing\n",
        "\n",
        "This cell handles the initial setup, including mounting Google Drive, loading the dataset, and performing essential preprocessing steps.\n",
        "\n",
        "- **Drive Mount:** Mounts the Google Drive to access the dataset file.\n",
        "- **Data Loading:** Loads the movie data from a CSV file into a pandas DataFrame.\n",
        "- **Association Rule Mining:**\n",
        "    - The `Output` column, containing comma-separated genres, is split into a list of genres for each movie.\n",
        "    - `TransactionEncoder` converts this list into a one-hot encoded format suitable for association rule mining.\n",
        "    - `fpgrowth` is used to find frequent itemsets of genres.\n",
        "    - `association_rules` generates rules based on these itemsets, which are then filtered for high confidence and support.\n",
        "- **Multi-Label Classification Preprocessing:**\n",
        "    - The `description` for each movie is extracted from the `Input` column.\n",
        "    - The `Output` column is converted into a list of genre labels.\n",
        "    - `MultiLabelBinarizer` transforms these genre lists into a binary matrix format, which is the standard for multi-label classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlxtend\n",
        "!pip install ltntorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRP__THJNFjt",
        "outputId": "ef952af8-e1d0-4d8d-a598-054b7a8c7ff1"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.5.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n",
            "Collecting ltntorch\n",
            "  Downloading LTNtorch-1.0.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ltntorch) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from ltntorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->ltntorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->ltntorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->ltntorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->ltntorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->ltntorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->ltntorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->ltntorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->ltntorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->ltntorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->ltntorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->ltntorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->ltntorch) (3.0.2)\n",
            "Downloading LTNtorch-1.0.2-py3-none-any.whl (29 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m58.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ltntorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed ltntorch-1.0.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2afdf29e",
        "outputId": "1e8bba5f-4b4f-4704-d810-d1581622ff75"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Load the data\n",
        "df = pd.read_csv('/content/drive/My Drive/movie-genre-prediction/train.csv')\n",
        "\n",
        "# Use only 25% of the dataset\n",
        "df = df.sample(frac=0.10, random_state=42).reset_index(drop=True)\n",
        "\n",
        "# Association rule mining\n",
        "transactions = df['expanded-genres'].str.split(', ').tolist()\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "frequent_itemsets = fpgrowth(df_encoded, min_support=0.01, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
        "high_confidence_rules = rules[(rules['confidence'] > 0.25) & (rules['support'] > 0.001)]\n",
        "\n",
        "# Data preprocessing for multi-label classification\n",
        "#df['description'] = df['Input'].apply(lambda x: x.split('\\n\\n', 1)[1] if '\\n\\n' in x else '')\n",
        "df['Output-Label'] = df['expanded-genres'].str.split(', ')\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(df['Output-Label'])\n",
        "\n",
        "# Display results\n",
        "display(df.head())\n",
        "display(high_confidence_rules)\n",
        "print(\"Descriptions:\")\n",
        "display(df['description'].head())\n",
        "print(\"\\nBinary Labels (y):\")\n",
        "display(y[:5])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "             movie title - year    genre             expanded-genres  rating  \\\n",
              "0  Mei shan shou qi guai - 1973  Fantasy  Action, Adventure, Fantasy     5.4   \n",
              "1            Money Fight - 2012   Action               Action, Drama     3.9   \n",
              "2           Dui Prithibi - 2010  Romance              Drama, Romance     6.4   \n",
              "3         The Barbarians - 1987  Fantasy  Action, Adventure, Fantasy     4.9   \n",
              "4         Bridge of Birds - nan  Fantasy  Action, Adventure, Fantasy     NaN   \n",
              "\n",
              "                                         description  \\\n",
              "0  Na Cha is sent to the land of the dead to figh...   \n",
              "1  This full-contact action drama, loaded with au...   \n",
              "2  Rahul, the son of a very rich man who has lost...   \n",
              "3  Two twin barbarians seek revenge from the warl...   \n",
              "4  When a farm boy's village is cursed by a myste...   \n",
              "\n",
              "                   Output-Label  \n",
              "0  [Action, Adventure, Fantasy]  \n",
              "1               [Action, Drama]  \n",
              "2              [Drama, Romance]  \n",
              "3  [Action, Adventure, Fantasy]  \n",
              "4  [Action, Adventure, Fantasy]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-aa0bdbbc-2176-4b8a-afb3-bf6d6fb92271\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie title - year</th>\n",
              "      <th>genre</th>\n",
              "      <th>expanded-genres</th>\n",
              "      <th>rating</th>\n",
              "      <th>description</th>\n",
              "      <th>Output-Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mei shan shou qi guai - 1973</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>Action, Adventure, Fantasy</td>\n",
              "      <td>5.4</td>\n",
              "      <td>Na Cha is sent to the land of the dead to figh...</td>\n",
              "      <td>[Action, Adventure, Fantasy]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Money Fight - 2012</td>\n",
              "      <td>Action</td>\n",
              "      <td>Action, Drama</td>\n",
              "      <td>3.9</td>\n",
              "      <td>This full-contact action drama, loaded with au...</td>\n",
              "      <td>[Action, Drama]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dui Prithibi - 2010</td>\n",
              "      <td>Romance</td>\n",
              "      <td>Drama, Romance</td>\n",
              "      <td>6.4</td>\n",
              "      <td>Rahul, the son of a very rich man who has lost...</td>\n",
              "      <td>[Drama, Romance]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>The Barbarians - 1987</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>Action, Adventure, Fantasy</td>\n",
              "      <td>4.9</td>\n",
              "      <td>Two twin barbarians seek revenge from the warl...</td>\n",
              "      <td>[Action, Adventure, Fantasy]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Bridge of Birds - nan</td>\n",
              "      <td>Fantasy</td>\n",
              "      <td>Action, Adventure, Fantasy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When a farm boy's village is cursed by a myste...</td>\n",
              "      <td>[Action, Adventure, Fantasy]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-aa0bdbbc-2176-4b8a-afb3-bf6d6fb92271')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-aa0bdbbc-2176-4b8a-afb3-bf6d6fb92271 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-aa0bdbbc-2176-4b8a-afb3-bf6d6fb92271');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-620fe06d-2cc4-4110-83cc-db49c1053dd9\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-620fe06d-2cc4-4110-83cc-db49c1053dd9')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-620fe06d-2cc4-4110-83cc-db49c1053dd9 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(y[:5])\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"movie title - year\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Money Fight - 2012\",\n          \"Bridge of Birds - nan\",\n          \"Dui Prithibi - 2010\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Fantasy\",\n          \"Action\",\n          \"Romance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expanded-genres\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"Action, Adventure, Fantasy\",\n          \"Action, Drama\",\n          \"Drama, Romance\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 1.0408329997330665,\n        \"min\": 3.9,\n        \"max\": 6.4,\n        \"num_unique_values\": 4,\n        \"samples\": [\n          3.9,\n          4.9,\n          5.4\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"This full-contact action drama, loaded with authentic mixed martial arts, is a transcending inspirational story of redemption.\",\n          \"When a farm boy's village is cursed by a mysterious plague, he enlists the help of a wise man with a slight flaw in his character. Together they venture into the enchanted realms of China to obtain the only cure from the evil Duke of Chin.\",\n          \"Rahul, the son of a very rich man who has lost his love sets out on a journey, and discovers his life anew in the process.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Output-Label\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               antecedents  consequents  antecedent support  \\\n",
              "0              (Adventure)     (Action)            0.174641   \n",
              "1                 (Action)  (Adventure)            0.286620   \n",
              "4      (Adventure, Comedy)     (Action)            0.040418   \n",
              "5         (Action, Comedy)  (Adventure)            0.044237   \n",
              "8       (Drama, Adventure)     (Action)            0.041803   \n",
              "10               (Fantasy)  (Adventure)            0.085621   \n",
              "17               (Romance)      (Drama)            0.160035   \n",
              "18                (Comedy)    (Romance)            0.191975   \n",
              "19               (Romance)     (Comedy)            0.160035   \n",
              "20         (Drama, Comedy)    (Romance)            0.050617   \n",
              "24                 (Crime)     (Action)            0.208260   \n",
              "25                (Action)      (Crime)            0.286620   \n",
              "26                 (Crime)      (Drama)            0.208260   \n",
              "27                 (Drama)      (Crime)            0.395786   \n",
              "28      (Thriller, Action)      (Crime)            0.045538   \n",
              "30       (Thriller, Drama)      (Crime)            0.060228   \n",
              "32         (Crime, Action)      (Drama)            0.074540   \n",
              "33         (Drama, Action)      (Crime)            0.088391   \n",
              "37               (Mystery)   (Thriller)            0.108369   \n",
              "39               (Mystery)      (Crime)            0.108369   \n",
              "41               (Mystery)     (Horror)            0.108369   \n",
              "43        (Crime, Mystery)      (Drama)            0.027827   \n",
              "44        (Mystery, Drama)      (Crime)            0.042013   \n",
              "49       (Horror, Mystery)   (Thriller)            0.034626   \n",
              "50     (Thriller, Mystery)     (Horror)            0.035591   \n",
              "54                (Sci-Fi)     (Action)            0.072400   \n",
              "58                   (War)      (Drama)            0.031478   \n",
              "60             (Animation)  (Adventure)            0.055528   \n",
              "62             (Animation)     (Action)            0.055528   \n",
              "66             (Animation)     (Comedy)            0.055528   \n",
              "68  (Animation, Adventure)     (Action)            0.028750   \n",
              "69     (Animation, Action)  (Adventure)            0.016537   \n",
              "74                (Horror)   (Thriller)            0.178461   \n",
              "75              (Thriller)     (Horror)            0.216570   \n",
              "77             (Biography)      (Drama)            0.038361   \n",
              "78                (Family)  (Adventure)            0.068371   \n",
              "80                (Family)     (Comedy)            0.068371   \n",
              "82               (History)      (Drama)            0.038529   \n",
              "\n",
              "    consequent support   support  confidence      lift  representativity  \\\n",
              "0             0.286620  0.084278    0.482576  1.683682               1.0   \n",
              "1             0.174641  0.084278    0.294040  1.683682               1.0   \n",
              "4             0.286620  0.013179    0.326064  1.137620               1.0   \n",
              "5             0.174641  0.013179    0.297913  1.705856               1.0   \n",
              "8             0.286620  0.014438    0.345382  1.205017               1.0   \n",
              "10            0.174641  0.023000    0.268627  1.538168               1.0   \n",
              "17            0.395786  0.091245    0.570155  1.440563               1.0   \n",
              "18            0.160035  0.049148    0.256012  1.599724               1.0   \n",
              "19            0.191975  0.049148    0.307107  1.599724               1.0   \n",
              "20            0.160035  0.016201    0.320066  1.999974               1.0   \n",
              "24            0.286620  0.074540    0.357920  1.248764               1.0   \n",
              "25            0.208260  0.074540    0.260067  1.248764               1.0   \n",
              "26            0.395786  0.107068    0.514107  1.298952               1.0   \n",
              "27            0.208260  0.107068    0.270520  1.298952               1.0   \n",
              "28            0.208260  0.013179    0.289401  1.389614               1.0   \n",
              "30            0.208260  0.015697    0.260627  1.251452               1.0   \n",
              "32            0.395786  0.029631    0.397523  1.004387               1.0   \n",
              "33            0.208260  0.029631    0.335233  1.609684               1.0   \n",
              "37            0.216570  0.035591    0.328428  1.516495               1.0   \n",
              "39            0.208260  0.027827    0.256778  1.232968               1.0   \n",
              "41            0.178461  0.034626    0.319520  1.790423               1.0   \n",
              "43            0.395786  0.011836    0.425339  1.074670               1.0   \n",
              "44            0.208260  0.011836    0.281718  1.352725               1.0   \n",
              "49            0.216570  0.013850    0.400000  1.846977               1.0   \n",
              "50            0.178461  0.013850    0.389151  2.180600               1.0   \n",
              "54            0.286620  0.021363    0.295072  1.029491               1.0   \n",
              "58            0.395786  0.021153    0.672000  1.697887               1.0   \n",
              "60            0.174641  0.028750    0.517763  2.964723               1.0   \n",
              "62            0.286620  0.016537    0.297808  1.039036               1.0   \n",
              "66            0.191975  0.015571    0.280423  1.460727               1.0   \n",
              "68            0.286620  0.010996    0.382482  1.334457               1.0   \n",
              "69            0.174641  0.010996    0.664975  3.807663               1.0   \n",
              "74            0.216570  0.057332    0.321261  1.483402               1.0   \n",
              "75            0.178461  0.057332    0.264729  1.483402               1.0   \n",
              "77            0.395786  0.026484    0.690372  1.744306               1.0   \n",
              "78            0.174641  0.020608    0.301412  1.725893               1.0   \n",
              "80            0.191975  0.019558    0.286065  1.490115               1.0   \n",
              "82            0.395786  0.027029    0.701525  1.772485               1.0   \n",
              "\n",
              "    leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
              "0   0.034222    1.378716       0.491984  0.223558   0.274687    0.388308  \n",
              "1   0.034222    1.169130       0.569210  0.223558   0.144663    0.388308  \n",
              "4   0.001594    1.058529       0.126068  0.041990   0.055293    0.186022  \n",
              "5   0.005453    1.175579       0.432936  0.064069   0.149355    0.186688  \n",
              "8   0.002456    1.089765       0.177559  0.045983   0.082371    0.197877  \n",
              "10  0.008047    1.128507       0.382638  0.096940   0.113873    0.200163  \n",
              "17  0.027905    1.405654       0.364095  0.196404   0.288588    0.400348  \n",
              "18  0.018425    1.129003       0.463961  0.162278   0.114263    0.281560  \n",
              "19  0.018425    1.166162       0.446319  0.162278   0.142486    0.281560  \n",
              "20  0.008100    1.235363       0.526651  0.083315   0.190521    0.210649  \n",
              "24  0.014849    1.111046       0.251608  0.177334   0.099947    0.308994  \n",
              "25  0.014849    1.070016       0.279245  0.177334   0.065435    0.308994  \n",
              "26  0.024642    1.243513       0.290687  0.215438   0.195827    0.392313  \n",
              "27  0.024642    1.085348       0.380906  0.215438   0.078637    0.392313  \n",
              "28  0.003695    1.114187       0.293753  0.054771   0.102484    0.176341  \n",
              "30  0.003154    1.070827       0.213805  0.062095   0.066142    0.168000  \n",
              "32  0.000129    1.002882       0.004720  0.067238   0.002874    0.236195  \n",
              "33  0.011223    1.191003       0.415485  0.110971   0.160372    0.238757  \n",
              "37  0.012122    1.166561       0.381980  0.123006   0.142779    0.246384  \n",
              "39  0.005258    1.065280       0.211914  0.096352   0.061280    0.195197  \n",
              "41  0.015286    1.207294       0.495129  0.137294   0.171701    0.256773  \n",
              "43  0.000822    1.051427       0.071470  0.028743   0.048912    0.227622  \n",
              "44  0.003086    1.102270       0.272187  0.049639   0.092781    0.169275  \n",
              "49  0.006351    1.305716       0.475023  0.058355   0.234137    0.231977  \n",
              "50  0.007499    1.344914       0.561391  0.069182   0.256458    0.233381  \n",
              "54  0.000612    1.011991       0.030882  0.063269   0.011849    0.184804  \n",
              "58  0.008695    1.842115       0.424392  0.052088   0.457146    0.362723  \n",
              "60  0.019053    1.711520       0.701662  0.142738   0.415724    0.341193  \n",
              "62  0.000621    1.015933       0.039778  0.050786   0.015684    0.177752  \n",
              "66  0.004911    1.122917       0.333953  0.067137   0.109462    0.180767  \n",
              "68  0.002756    1.155238       0.258051  0.036128   0.134377    0.210424  \n",
              "69  0.008108    2.463571       0.749770  0.061030   0.594085    0.363970  \n",
              "74  0.018683    1.154242       0.396663  0.169774   0.133631    0.292995  \n",
              "75  0.018683    1.117328       0.415958  0.169774   0.105008    0.292995  \n",
              "77  0.011301    1.951419       0.443728  0.064964   0.487552    0.378643  \n",
              "78  0.008667    1.181467       0.451456  0.092659   0.153595    0.209706  \n",
              "80  0.006433    1.131791       0.353049  0.081227   0.116444    0.193973  \n",
              "82  0.011780    2.024337       0.453285  0.066364   0.506011    0.384909  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5529316e-7cab-468f-a564-4cc6999449eb\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>antecedents</th>\n",
              "      <th>consequents</th>\n",
              "      <th>antecedent support</th>\n",
              "      <th>consequent support</th>\n",
              "      <th>support</th>\n",
              "      <th>confidence</th>\n",
              "      <th>lift</th>\n",
              "      <th>representativity</th>\n",
              "      <th>leverage</th>\n",
              "      <th>conviction</th>\n",
              "      <th>zhangs_metric</th>\n",
              "      <th>jaccard</th>\n",
              "      <th>certainty</th>\n",
              "      <th>kulczynski</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.174641</td>\n",
              "      <td>0.286620</td>\n",
              "      <td>0.084278</td>\n",
              "      <td>0.482576</td>\n",
              "      <td>1.683682</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.034222</td>\n",
              "      <td>1.378716</td>\n",
              "      <td>0.491984</td>\n",
              "      <td>0.223558</td>\n",
              "      <td>0.274687</td>\n",
              "      <td>0.388308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>(Action)</td>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>0.286620</td>\n",
              "      <td>0.174641</td>\n",
              "      <td>0.084278</td>\n",
              "      <td>0.294040</td>\n",
              "      <td>1.683682</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.034222</td>\n",
              "      <td>1.169130</td>\n",
              "      <td>0.569210</td>\n",
              "      <td>0.223558</td>\n",
              "      <td>0.144663</td>\n",
              "      <td>0.388308</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>(Adventure, Comedy)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.040418</td>\n",
              "      <td>0.286620</td>\n",
              "      <td>0.013179</td>\n",
              "      <td>0.326064</td>\n",
              "      <td>1.137620</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001594</td>\n",
              "      <td>1.058529</td>\n",
              "      <td>0.126068</td>\n",
              "      <td>0.041990</td>\n",
              "      <td>0.055293</td>\n",
              "      <td>0.186022</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(Action, Comedy)</td>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>0.044237</td>\n",
              "      <td>0.174641</td>\n",
              "      <td>0.013179</td>\n",
              "      <td>0.297913</td>\n",
              "      <td>1.705856</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.005453</td>\n",
              "      <td>1.175579</td>\n",
              "      <td>0.432936</td>\n",
              "      <td>0.064069</td>\n",
              "      <td>0.149355</td>\n",
              "      <td>0.186688</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>(Drama, Adventure)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.041803</td>\n",
              "      <td>0.286620</td>\n",
              "      <td>0.014438</td>\n",
              "      <td>0.345382</td>\n",
              "      <td>1.205017</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.002456</td>\n",
              "      <td>1.089765</td>\n",
              "      <td>0.177559</td>\n",
              "      <td>0.045983</td>\n",
              "      <td>0.082371</td>\n",
              "      <td>0.197877</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>(Fantasy)</td>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>0.085621</td>\n",
              "      <td>0.174641</td>\n",
              "      <td>0.023000</td>\n",
              "      <td>0.268627</td>\n",
              "      <td>1.538168</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.008047</td>\n",
              "      <td>1.128507</td>\n",
              "      <td>0.382638</td>\n",
              "      <td>0.096940</td>\n",
              "      <td>0.113873</td>\n",
              "      <td>0.200163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>(Romance)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.160035</td>\n",
              "      <td>0.395786</td>\n",
              "      <td>0.091245</td>\n",
              "      <td>0.570155</td>\n",
              "      <td>1.440563</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.027905</td>\n",
              "      <td>1.405654</td>\n",
              "      <td>0.364095</td>\n",
              "      <td>0.196404</td>\n",
              "      <td>0.288588</td>\n",
              "      <td>0.400348</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>(Comedy)</td>\n",
              "      <td>(Romance)</td>\n",
              "      <td>0.191975</td>\n",
              "      <td>0.160035</td>\n",
              "      <td>0.049148</td>\n",
              "      <td>0.256012</td>\n",
              "      <td>1.599724</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.018425</td>\n",
              "      <td>1.129003</td>\n",
              "      <td>0.463961</td>\n",
              "      <td>0.162278</td>\n",
              "      <td>0.114263</td>\n",
              "      <td>0.281560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>(Romance)</td>\n",
              "      <td>(Comedy)</td>\n",
              "      <td>0.160035</td>\n",
              "      <td>0.191975</td>\n",
              "      <td>0.049148</td>\n",
              "      <td>0.307107</td>\n",
              "      <td>1.599724</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.018425</td>\n",
              "      <td>1.166162</td>\n",
              "      <td>0.446319</td>\n",
              "      <td>0.162278</td>\n",
              "      <td>0.142486</td>\n",
              "      <td>0.281560</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>(Drama, Comedy)</td>\n",
              "      <td>(Romance)</td>\n",
              "      <td>0.050617</td>\n",
              "      <td>0.160035</td>\n",
              "      <td>0.016201</td>\n",
              "      <td>0.320066</td>\n",
              "      <td>1.999974</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.008100</td>\n",
              "      <td>1.235363</td>\n",
              "      <td>0.526651</td>\n",
              "      <td>0.083315</td>\n",
              "      <td>0.190521</td>\n",
              "      <td>0.210649</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>(Crime)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.208260</td>\n",
              "      <td>0.286620</td>\n",
              "      <td>0.074540</td>\n",
              "      <td>0.357920</td>\n",
              "      <td>1.248764</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.014849</td>\n",
              "      <td>1.111046</td>\n",
              "      <td>0.251608</td>\n",
              "      <td>0.177334</td>\n",
              "      <td>0.099947</td>\n",
              "      <td>0.308994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>(Action)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.286620</td>\n",
              "      <td>0.208260</td>\n",
              "      <td>0.074540</td>\n",
              "      <td>0.260067</td>\n",
              "      <td>1.248764</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.014849</td>\n",
              "      <td>1.070016</td>\n",
              "      <td>0.279245</td>\n",
              "      <td>0.177334</td>\n",
              "      <td>0.065435</td>\n",
              "      <td>0.308994</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>(Crime)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.208260</td>\n",
              "      <td>0.395786</td>\n",
              "      <td>0.107068</td>\n",
              "      <td>0.514107</td>\n",
              "      <td>1.298952</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.024642</td>\n",
              "      <td>1.243513</td>\n",
              "      <td>0.290687</td>\n",
              "      <td>0.215438</td>\n",
              "      <td>0.195827</td>\n",
              "      <td>0.392313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>(Drama)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.395786</td>\n",
              "      <td>0.208260</td>\n",
              "      <td>0.107068</td>\n",
              "      <td>0.270520</td>\n",
              "      <td>1.298952</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.024642</td>\n",
              "      <td>1.085348</td>\n",
              "      <td>0.380906</td>\n",
              "      <td>0.215438</td>\n",
              "      <td>0.078637</td>\n",
              "      <td>0.392313</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>(Thriller, Action)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.045538</td>\n",
              "      <td>0.208260</td>\n",
              "      <td>0.013179</td>\n",
              "      <td>0.289401</td>\n",
              "      <td>1.389614</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.003695</td>\n",
              "      <td>1.114187</td>\n",
              "      <td>0.293753</td>\n",
              "      <td>0.054771</td>\n",
              "      <td>0.102484</td>\n",
              "      <td>0.176341</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>(Thriller, Drama)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.060228</td>\n",
              "      <td>0.208260</td>\n",
              "      <td>0.015697</td>\n",
              "      <td>0.260627</td>\n",
              "      <td>1.251452</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.003154</td>\n",
              "      <td>1.070827</td>\n",
              "      <td>0.213805</td>\n",
              "      <td>0.062095</td>\n",
              "      <td>0.066142</td>\n",
              "      <td>0.168000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>(Crime, Action)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.074540</td>\n",
              "      <td>0.395786</td>\n",
              "      <td>0.029631</td>\n",
              "      <td>0.397523</td>\n",
              "      <td>1.004387</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000129</td>\n",
              "      <td>1.002882</td>\n",
              "      <td>0.004720</td>\n",
              "      <td>0.067238</td>\n",
              "      <td>0.002874</td>\n",
              "      <td>0.236195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>(Drama, Action)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.088391</td>\n",
              "      <td>0.208260</td>\n",
              "      <td>0.029631</td>\n",
              "      <td>0.335233</td>\n",
              "      <td>1.609684</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.011223</td>\n",
              "      <td>1.191003</td>\n",
              "      <td>0.415485</td>\n",
              "      <td>0.110971</td>\n",
              "      <td>0.160372</td>\n",
              "      <td>0.238757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>(Mystery)</td>\n",
              "      <td>(Thriller)</td>\n",
              "      <td>0.108369</td>\n",
              "      <td>0.216570</td>\n",
              "      <td>0.035591</td>\n",
              "      <td>0.328428</td>\n",
              "      <td>1.516495</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.012122</td>\n",
              "      <td>1.166561</td>\n",
              "      <td>0.381980</td>\n",
              "      <td>0.123006</td>\n",
              "      <td>0.142779</td>\n",
              "      <td>0.246384</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>(Mystery)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.108369</td>\n",
              "      <td>0.208260</td>\n",
              "      <td>0.027827</td>\n",
              "      <td>0.256778</td>\n",
              "      <td>1.232968</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.005258</td>\n",
              "      <td>1.065280</td>\n",
              "      <td>0.211914</td>\n",
              "      <td>0.096352</td>\n",
              "      <td>0.061280</td>\n",
              "      <td>0.195197</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>(Mystery)</td>\n",
              "      <td>(Horror)</td>\n",
              "      <td>0.108369</td>\n",
              "      <td>0.178461</td>\n",
              "      <td>0.034626</td>\n",
              "      <td>0.319520</td>\n",
              "      <td>1.790423</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.015286</td>\n",
              "      <td>1.207294</td>\n",
              "      <td>0.495129</td>\n",
              "      <td>0.137294</td>\n",
              "      <td>0.171701</td>\n",
              "      <td>0.256773</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>(Crime, Mystery)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.027827</td>\n",
              "      <td>0.395786</td>\n",
              "      <td>0.011836</td>\n",
              "      <td>0.425339</td>\n",
              "      <td>1.074670</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000822</td>\n",
              "      <td>1.051427</td>\n",
              "      <td>0.071470</td>\n",
              "      <td>0.028743</td>\n",
              "      <td>0.048912</td>\n",
              "      <td>0.227622</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>(Mystery, Drama)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.042013</td>\n",
              "      <td>0.208260</td>\n",
              "      <td>0.011836</td>\n",
              "      <td>0.281718</td>\n",
              "      <td>1.352725</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.003086</td>\n",
              "      <td>1.102270</td>\n",
              "      <td>0.272187</td>\n",
              "      <td>0.049639</td>\n",
              "      <td>0.092781</td>\n",
              "      <td>0.169275</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>(Horror, Mystery)</td>\n",
              "      <td>(Thriller)</td>\n",
              "      <td>0.034626</td>\n",
              "      <td>0.216570</td>\n",
              "      <td>0.013850</td>\n",
              "      <td>0.400000</td>\n",
              "      <td>1.846977</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006351</td>\n",
              "      <td>1.305716</td>\n",
              "      <td>0.475023</td>\n",
              "      <td>0.058355</td>\n",
              "      <td>0.234137</td>\n",
              "      <td>0.231977</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>(Thriller, Mystery)</td>\n",
              "      <td>(Horror)</td>\n",
              "      <td>0.035591</td>\n",
              "      <td>0.178461</td>\n",
              "      <td>0.013850</td>\n",
              "      <td>0.389151</td>\n",
              "      <td>2.180600</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007499</td>\n",
              "      <td>1.344914</td>\n",
              "      <td>0.561391</td>\n",
              "      <td>0.069182</td>\n",
              "      <td>0.256458</td>\n",
              "      <td>0.233381</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>(Sci-Fi)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.072400</td>\n",
              "      <td>0.286620</td>\n",
              "      <td>0.021363</td>\n",
              "      <td>0.295072</td>\n",
              "      <td>1.029491</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000612</td>\n",
              "      <td>1.011991</td>\n",
              "      <td>0.030882</td>\n",
              "      <td>0.063269</td>\n",
              "      <td>0.011849</td>\n",
              "      <td>0.184804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>(War)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.031478</td>\n",
              "      <td>0.395786</td>\n",
              "      <td>0.021153</td>\n",
              "      <td>0.672000</td>\n",
              "      <td>1.697887</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.008695</td>\n",
              "      <td>1.842115</td>\n",
              "      <td>0.424392</td>\n",
              "      <td>0.052088</td>\n",
              "      <td>0.457146</td>\n",
              "      <td>0.362723</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>(Animation)</td>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>0.055528</td>\n",
              "      <td>0.174641</td>\n",
              "      <td>0.028750</td>\n",
              "      <td>0.517763</td>\n",
              "      <td>2.964723</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.019053</td>\n",
              "      <td>1.711520</td>\n",
              "      <td>0.701662</td>\n",
              "      <td>0.142738</td>\n",
              "      <td>0.415724</td>\n",
              "      <td>0.341193</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>(Animation)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.055528</td>\n",
              "      <td>0.286620</td>\n",
              "      <td>0.016537</td>\n",
              "      <td>0.297808</td>\n",
              "      <td>1.039036</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000621</td>\n",
              "      <td>1.015933</td>\n",
              "      <td>0.039778</td>\n",
              "      <td>0.050786</td>\n",
              "      <td>0.015684</td>\n",
              "      <td>0.177752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>(Animation)</td>\n",
              "      <td>(Comedy)</td>\n",
              "      <td>0.055528</td>\n",
              "      <td>0.191975</td>\n",
              "      <td>0.015571</td>\n",
              "      <td>0.280423</td>\n",
              "      <td>1.460727</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.004911</td>\n",
              "      <td>1.122917</td>\n",
              "      <td>0.333953</td>\n",
              "      <td>0.067137</td>\n",
              "      <td>0.109462</td>\n",
              "      <td>0.180767</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>(Animation, Adventure)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.028750</td>\n",
              "      <td>0.286620</td>\n",
              "      <td>0.010996</td>\n",
              "      <td>0.382482</td>\n",
              "      <td>1.334457</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.002756</td>\n",
              "      <td>1.155238</td>\n",
              "      <td>0.258051</td>\n",
              "      <td>0.036128</td>\n",
              "      <td>0.134377</td>\n",
              "      <td>0.210424</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>(Animation, Action)</td>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>0.016537</td>\n",
              "      <td>0.174641</td>\n",
              "      <td>0.010996</td>\n",
              "      <td>0.664975</td>\n",
              "      <td>3.807663</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.008108</td>\n",
              "      <td>2.463571</td>\n",
              "      <td>0.749770</td>\n",
              "      <td>0.061030</td>\n",
              "      <td>0.594085</td>\n",
              "      <td>0.363970</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>(Horror)</td>\n",
              "      <td>(Thriller)</td>\n",
              "      <td>0.178461</td>\n",
              "      <td>0.216570</td>\n",
              "      <td>0.057332</td>\n",
              "      <td>0.321261</td>\n",
              "      <td>1.483402</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.018683</td>\n",
              "      <td>1.154242</td>\n",
              "      <td>0.396663</td>\n",
              "      <td>0.169774</td>\n",
              "      <td>0.133631</td>\n",
              "      <td>0.292995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>(Thriller)</td>\n",
              "      <td>(Horror)</td>\n",
              "      <td>0.216570</td>\n",
              "      <td>0.178461</td>\n",
              "      <td>0.057332</td>\n",
              "      <td>0.264729</td>\n",
              "      <td>1.483402</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.018683</td>\n",
              "      <td>1.117328</td>\n",
              "      <td>0.415958</td>\n",
              "      <td>0.169774</td>\n",
              "      <td>0.105008</td>\n",
              "      <td>0.292995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>(Biography)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.038361</td>\n",
              "      <td>0.395786</td>\n",
              "      <td>0.026484</td>\n",
              "      <td>0.690372</td>\n",
              "      <td>1.744306</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.011301</td>\n",
              "      <td>1.951419</td>\n",
              "      <td>0.443728</td>\n",
              "      <td>0.064964</td>\n",
              "      <td>0.487552</td>\n",
              "      <td>0.378643</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>(Family)</td>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>0.068371</td>\n",
              "      <td>0.174641</td>\n",
              "      <td>0.020608</td>\n",
              "      <td>0.301412</td>\n",
              "      <td>1.725893</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.008667</td>\n",
              "      <td>1.181467</td>\n",
              "      <td>0.451456</td>\n",
              "      <td>0.092659</td>\n",
              "      <td>0.153595</td>\n",
              "      <td>0.209706</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>(Family)</td>\n",
              "      <td>(Comedy)</td>\n",
              "      <td>0.068371</td>\n",
              "      <td>0.191975</td>\n",
              "      <td>0.019558</td>\n",
              "      <td>0.286065</td>\n",
              "      <td>1.490115</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006433</td>\n",
              "      <td>1.131791</td>\n",
              "      <td>0.353049</td>\n",
              "      <td>0.081227</td>\n",
              "      <td>0.116444</td>\n",
              "      <td>0.193973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>(History)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.038529</td>\n",
              "      <td>0.395786</td>\n",
              "      <td>0.027029</td>\n",
              "      <td>0.701525</td>\n",
              "      <td>1.772485</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.011780</td>\n",
              "      <td>2.024337</td>\n",
              "      <td>0.453285</td>\n",
              "      <td>0.066364</td>\n",
              "      <td>0.506011</td>\n",
              "      <td>0.384909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5529316e-7cab-468f-a564-4cc6999449eb')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-5529316e-7cab-468f-a564-4cc6999449eb button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-5529316e-7cab-468f-a564-4cc6999449eb');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-0ea62a85-efda-4522-a8cf-73801df45c19\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-0ea62a85-efda-4522-a8cf-73801df45c19')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-0ea62a85-efda-4522-a8cf-73801df45c19 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_86cfbe56-2919-4f92-8764-efbba7a4f72a\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('high_confidence_rules')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_86cfbe56-2919-4f92-8764-efbba7a4f72a button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('high_confidence_rules');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "high_confidence_rules",
              "summary": "{\n  \"name\": \"high_confidence_rules\",\n  \"rows\": 38,\n  \"fields\": [\n    {\n      \"column\": \"antecedents\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 30,\n        \"samples\": [\n          \"frozenset({'Biography'})\",\n          \"frozenset({'Mystery'})\",\n          \"frozenset({'Animation', 'Adventure'})\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"consequents\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"frozenset({'Adventure'})\",\n          \"frozenset({'Crime'})\",\n          \"frozenset({'Action'})\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"antecedent support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08835179901477914,\n        \"min\": 0.01653655670276169,\n        \"max\": 0.3957861160077227,\n        \"num_unique_values\": 30,\n        \"samples\": [\n          0.038361453873919246,\n          0.10836900864601695,\n          0.028750104927390246\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"consequent support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0820244225056904,\n        \"min\": 0.16003525560312265,\n        \"max\": 0.3957861160077227,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.17464114832535885,\n          0.20825988416016117,\n          0.2866196591958365\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028735687678837357,\n        \"min\": 0.01099639049777554,\n        \"max\": 0.10706790900696718,\n        \"num_unique_values\": 27,\n        \"samples\": [\n          0.10706790900696718,\n          0.03462603878116344,\n          0.01569713758079409\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13198486050205255,\n        \"min\": 0.2560122431132488,\n        \"max\": 0.701525054466231,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          0.26472868217054263,\n          0.28606507059545727,\n          0.3453815261044177\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lift\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5201241307802664,\n        \"min\": 1.0043872345303946,\n        \"max\": 3.8076628885334816,\n        \"num_unique_values\": 35,\n        \"samples\": [\n          1.0390355390459987,\n          1.2514516597921204,\n          1.6978867444326617\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"representativity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leverage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.009173696877588393,\n        \"min\": 0.00012943246748444923,\n        \"max\": 0.034222093430962996,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          0.006432992338075658\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conviction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.3190628527750459,\n        \"min\": 1.0028821102526022,\n        \"max\": 2.463571117877338,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          1.117328358591353\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"zhangs_metric\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1715077923763286,\n        \"min\": 0.004719893623171533,\n        \"max\": 0.7497703277829757,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          0.41595801607012006\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jaccard\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06068086470655067,\n        \"min\": 0.028743247375394965,\n        \"max\": 0.22355822756624358,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          0.08122712218929755\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"certainty\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.1438725592175579,\n        \"min\": 0.0028738275647138744,\n        \"max\": 0.5940851909070846,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          0.10500794837004948\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kulczynski\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07927931038750938,\n        \"min\": 0.1680000056176067,\n        \"max\": 0.4003477804764022,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          0.19397263149361843\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descriptions:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    Na Cha is sent to the land of the dead to figh...\n",
              "1    This full-contact action drama, loaded with au...\n",
              "2    Rahul, the son of a very rich man who has lost...\n",
              "3    Two twin barbarians seek revenge from the warl...\n",
              "4    When a farm boy's village is cursed by a myste...\n",
              "Name: description, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Na Cha is sent to the land of the dead to figh...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>This full-contact action drama, loaded with au...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Rahul, the son of a very rich man who has lost...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Two twin barbarians seek revenge from the warl...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>When a farm boy's village is cursed by a myste...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Binary Labels (y):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0]])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8fffe5a"
      },
      "source": [
        "### 2. Baseline Model Training\n",
        "\n",
        "This cell defines and trains a baseline multi-label classification model using a pre-trained DistilBERT model.\n",
        "\n",
        "- **Device Configuration:** Sets the device to \"cuda\" if a GPU is available, otherwise \"cpu\".\n",
        "- **Tokenizer and Model Loading:** Loads the \"distilbert-base-uncased\" tokenizer and model from the Hugging Face library.\n",
        "- **Model Definition:**\n",
        "    - A `BaselineMovieClassifier` class is defined, which includes the DistilBERT model and a linear classifier layer.\n",
        "    - The model takes tokenized input and produces logits for each genre.\n",
        "- **Training Setup:**\n",
        "    - The model, loss function (BCEWithLogitsLoss), and optimizer (Adam) are initialized.\n",
        "- **Data Preparation:**\n",
        "    - The movie descriptions are tokenized using the DistilBERT tokenizer.\n",
        "    - The data is split into training and testing sets.\n",
        "    - A DataLoader is created for the training data to handle batching and shuffling.\n",
        "- **Training Loop:**\n",
        "    - The model is trained for 10 epochs.\n",
        "    - In each epoch, the model processes batches of data, calculates the loss, and updates its weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de410944",
        "outputId": "95e3184f-93be-4415-c38a-188e07881860"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Tokenizer and model\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "transformer_model = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
        "\n",
        "# Classifier model\n",
        "class BaselineMovieClassifier(nn.Module):\n",
        "    def __init__(self, transformer_model, num_labels, dropout=0.3):\n",
        "        super(BaselineMovieClassifier, self).__init__()\n",
        "        self.transformer = transformer_model\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(transformer_model.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "        x = self.dropout(embeddings)\n",
        "        logits = self.classifier(x)\n",
        "        return logits\n",
        "\n",
        "# Prepare data and labels (assumes mlb and df already defined)\n",
        "num_genres = len(mlb.classes_)\n",
        "baseline_model = BaselineMovieClassifier(transformer_model, num_genres).to(device)\n",
        "\n",
        "X = tokenizer(\n",
        "    text=df['description'].tolist(),\n",
        "    add_special_tokens=True,\n",
        "    max_length=128,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt',\n",
        "    return_token_type_ids=False,\n",
        "    return_attention_mask=True,\n",
        "    verbose=True\n",
        ")\n",
        "input_ids = X['input_ids']\n",
        "attention_mask = X['attention_mask']\n",
        "\n",
        "# Split train+val/test\n",
        "X_train_val_ids, X_test_ids, y_train_val, y_test, X_train_val_mask, X_test_mask = train_test_split(\n",
        "    input_ids, y, attention_mask, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Further split train into train and val (10% val)\n",
        "X_train_ids, X_val_ids, y_train, y_val, X_train_mask, X_val_mask = train_test_split(\n",
        "    X_train_val_ids, y_train_val, X_train_val_mask, test_size=0.125, random_state=42\n",
        ")\n",
        "\n",
        "# Calculate pos_weight on training labels\n",
        "positive_counts = np.sum(y_train, axis=0)\n",
        "total_counts = y_train.shape[0]\n",
        "negative_counts = total_counts - positive_counts\n",
        "epsilon = 1e-5\n",
        "pos_weights = torch.tensor(negative_counts / (positive_counts + epsilon), dtype=torch.float32).to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
        "\n",
        "# Hyperparams\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "optimizer = optim.Adam(baseline_model.parameters(), lr=3e-5, weight_decay=0.01)\n",
        "total_steps = (len(X_train_ids) // batch_size + 1) * epochs\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(\n",
        "    X_train_ids.to(device),\n",
        "    X_train_mask.to(device),\n",
        "    torch.tensor(y_train, dtype=torch.float32).to(device)\n",
        ")\n",
        "val_dataset = torch.utils.data.TensorDataset(\n",
        "    X_val_ids.to(device),\n",
        "    X_val_mask.to(device),\n",
        "    torch.tensor(y_val, dtype=torch.float32).to(device)\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    preds = []\n",
        "    targets = []\n",
        "    with torch.no_grad():\n",
        "        for batch_input_ids, batch_attention_mask, batch_y_true in loader:\n",
        "            logits = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "            loss = criterion(logits, batch_y_true)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            y_pred = torch.sigmoid(logits).cpu().numpy()\n",
        "            preds.append(y_pred)\n",
        "            targets.append(batch_y_true.cpu().numpy())\n",
        "\n",
        "    avg_loss = np.mean(losses)\n",
        "    preds = np.vstack(preds)\n",
        "    targets = np.vstack(targets)\n",
        "    # Binarize preds with 0.5 threshold for metric\n",
        "    preds_binary = (preds > 0.5).astype(int)\n",
        "\n",
        "    f1 = f1_score(targets, preds_binary, average='micro', zero_division=0)\n",
        "    return avg_loss, f1\n",
        "\n",
        "# early-stopping\n",
        "best_val_f1 = 0.0\n",
        "patience = 3  # Number of epochs to wait before stopping\n",
        "epochs_without_improvement = 0\n",
        "best_model_state = None  # To store best model\n",
        "\n",
        "# Training loop with validation\n",
        "for epoch in range(epochs):\n",
        "    baseline_model.train()\n",
        "    total_loss = 0\n",
        "    for batch_input_ids, batch_attention_mask, batch_y_true in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = baseline_model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        loss = criterion(logits, batch_y_true)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(baseline_model.parameters(), max_grad_norm)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    train_loss = total_loss / len(train_loader)\n",
        "    val_loss, val_f1 = evaluate(baseline_model, val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Micro F1: {val_f1:.4f}\")\n",
        "\n",
        "    # --- Early Stopping Logic ---\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        epochs_without_improvement = 0\n",
        "        best_model_state = baseline_model.state_dict()  # Save best model\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(f\"\\nEarly stopping triggered. Best Val F1: {best_val_f1:.4f}\")\n",
        "            break\n",
        "\n",
        "if best_model_state:\n",
        "    baseline_model.load_state_dict(best_model_state)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Epoch 1/10 | Train Loss: 1.2341 | Val Loss: 0.8683 | Val Micro F1: 0.3810\n",
            "Epoch 2/10 | Train Loss: 1.1064 | Val Loss: 0.7957 | Val Micro F1: 0.3924\n",
            "Epoch 3/10 | Train Loss: 1.0793 | Val Loss: 0.8321 | Val Micro F1: 0.3986\n",
            "Epoch 4/10 | Train Loss: 1.0711 | Val Loss: 0.7957 | Val Micro F1: 0.3997\n",
            "Epoch 5/10 | Train Loss: 1.0920 | Val Loss: 0.8161 | Val Micro F1: 0.4024\n",
            "Epoch 6/10 | Train Loss: 1.0346 | Val Loss: 0.8071 | Val Micro F1: 0.3961\n",
            "Epoch 7/10 | Train Loss: 0.9823 | Val Loss: 0.8181 | Val Micro F1: 0.3882\n",
            "Epoch 8/10 | Train Loss: 0.9515 | Val Loss: 0.8388 | Val Micro F1: 0.4240\n",
            "Epoch 9/10 | Train Loss: 0.9759 | Val Loss: 0.8206 | Val Micro F1: 0.4163\n",
            "Epoch 10/10 | Train Loss: 0.9171 | Val Loss: 0.8242 | Val Micro F1: 0.4225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "334bea93"
      },
      "source": [
        "### 3. Baseline Model Evaluation\n",
        "\n",
        "This cell evaluates the performance of the trained baseline model on the test set.\n",
        "\n",
        "- **Evaluation Mode:** The model is set to evaluation mode using `baseline_model.eval()`.\n",
        "- **Prediction:** The model makes predictions on the test data.\n",
        "- **Classification Report:** A classification report is printed, showing precision, recall, and F1-score for each genre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da93fe8d",
        "outputId": "8490d25b-f5f0-4920-d2d5-d88307e8ca30"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Create test dataset with attention mask\n",
        "test_dataset = TensorDataset(\n",
        "    X_test_ids.to(device),\n",
        "    X_test_mask.to(device),\n",
        "    torch.tensor(y_test, dtype=torch.float32).to(device)\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Evaluation\n",
        "baseline_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_input_ids, batch_attention_mask, batch_y_true in test_loader:\n",
        "        # Pass attention mask to model\n",
        "        logits = baseline_model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.6).cpu().numpy()\n",
        "\n",
        "        all_preds.append(preds)\n",
        "        all_labels.append(batch_y_true.cpu().numpy())\n",
        "\n",
        "# Concatenate predictions and labels\n",
        "import numpy as np\n",
        "y_pred_binary = np.vstack(all_preds)\n",
        "y_true = np.vstack(all_labels)\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(y_true, y_pred_binary, target_names=mlb.classes_, zero_division=0))\n",
        "print(\"Avg predicted labels per sample:\", y_pred_binary.sum(axis=1).mean())\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Action       0.55      0.56      0.56      1368\n",
            "   Adventure       0.42      0.55      0.47       837\n",
            "   Animation       0.22      0.68      0.34       262\n",
            "   Biography       0.22      0.69      0.33       170\n",
            "      Comedy       0.40      0.33      0.36       934\n",
            "       Crime       0.50      0.64      0.56      1017\n",
            "       Drama       0.60      0.33      0.42      1869\n",
            "      Family       0.24      0.57      0.33       340\n",
            "     Fantasy       0.23      0.57      0.32       437\n",
            "   Film-Noir       0.05      0.56      0.09        32\n",
            "     History       0.26      0.71      0.38       194\n",
            "      Horror       0.45      0.72      0.56       877\n",
            "       Music       0.11      0.47      0.18        88\n",
            "     Musical       0.05      0.44      0.10        48\n",
            "     Mystery       0.24      0.60      0.35       524\n",
            "  Reality-TV       0.00      0.00      0.00         0\n",
            "     Romance       0.44      0.54      0.48       756\n",
            "      Sci-Fi       0.24      0.72      0.36       344\n",
            "       Short       0.00      0.00      0.00         0\n",
            "       Sport       0.25      0.67      0.36        64\n",
            "   Talk-Show       0.00      0.00      0.00         0\n",
            "    Thriller       0.38      0.58      0.46      1045\n",
            "         War       0.26      0.79      0.39       140\n",
            "     Western       0.18      0.49      0.26        41\n",
            "\n",
            "   micro avg       0.35      0.54      0.43     11387\n",
            "   macro avg       0.26      0.51      0.32     11387\n",
            "weighted avg       0.42      0.54      0.45     11387\n",
            " samples avg       0.36      0.56      0.40     11387\n",
            "\n",
            "Avg predicted labels per sample: 3.656105749055812\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04dd683f"
      },
      "source": [
        "### 4. Baseline Model Prediction on Evaluation Set\n",
        "\n",
        "This cell uses the trained baseline model to make predictions on a separate evaluation dataset.\n",
        "\n",
        "- **Load Evaluation Data:** Loads the evaluation dataset from a CSV file.\n",
        "- **Preprocess Evaluation Data:** The descriptions from the evaluation data are tokenized.\n",
        "- **Make Predictions:** The model predicts genres for the evaluation data.\n",
        "- **Store Predictions:** The predicted genres are added as a new column to the evaluation DataFrame.\n",
        "- **Classification Report:** A classification report is generated to evaluate the model's performance on this new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 814
        },
        "id": "13fcf9a0",
        "outputId": "145d9675-4fea-40f4-fb10-b93c38228dcf"
      },
      "source": [
        "# Load the evaluation data\n",
        "eval_df = pd.read_csv('/content/drive/My Drive/movie-genre-prediction/test.csv')\n",
        "\n",
        "# Preprocess the evaluation data\n",
        "eval_descriptions = eval_df['description'].tolist()\n",
        "eval_X = tokenizer(\n",
        "    text=eval_descriptions,\n",
        "    add_special_tokens=True,\n",
        "    max_length=128,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "# Move data to device\n",
        "eval_input_ids = eval_X['input_ids']\n",
        "eval_attention_mask = eval_X['attention_mask']\n",
        "\n",
        "# Create dataset and loader\n",
        "eval_dataset = TensorDataset(eval_input_ids, eval_attention_mask)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=32)  # use smaller batch_size if needed\n",
        "\n",
        "# Predict in batches\n",
        "baseline_model.eval()\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_ids, batch_mask in eval_loader:\n",
        "        batch_ids = batch_ids.to(device)\n",
        "        batch_mask = batch_mask.to(device)\n",
        "\n",
        "        logits = baseline_model(batch_ids, attention_mask=batch_mask)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        batch_preds = (probs > 0.5).cpu().numpy()\n",
        "        all_preds.append(batch_preds)\n",
        "\n",
        "# Final predictions\n",
        "import numpy as np\n",
        "predicted_labels_binary = np.vstack(all_preds)\n",
        "\n",
        "# Convert binary predictions to genre labels\n",
        "predicted_labels = mlb.inverse_transform(predicted_labels_binary)\n",
        "\n",
        "# Attach predictions to dataframe\n",
        "eval_df['predicted_genres_baseline'] = predicted_labels\n",
        "\n",
        "# Get true labels from CSV\n",
        "y_true_eval = mlb.transform(eval_df['expanded-genres'].str.split(', '))\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report for baseline model on the evaluation set:\")\n",
        "print(classification_report(y_true_eval, predicted_labels_binary, target_names=mlb.classes_, zero_division=0))\n",
        "\n",
        "# Optional: View predictions\n",
        "display(eval_df.head())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for baseline model on the evaluation set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Action       0.46      0.78      0.58      8550\n",
            "   Adventure       0.33      0.71      0.45      5112\n",
            "   Animation       0.18      0.78      0.29      1591\n",
            "   Biography       0.17      0.72      0.27      1117\n",
            "      Comedy       0.32      0.57      0.41      5738\n",
            "       Crime       0.40      0.77      0.53      6069\n",
            "       Drama       0.55      0.59      0.57     11998\n",
            "      Family       0.19      0.73      0.30      2102\n",
            "     Fantasy       0.18      0.73      0.29      2603\n",
            "   Film-Noir       0.05      0.67      0.09       237\n",
            "     History       0.22      0.75      0.33      1255\n",
            "      Horror       0.35      0.83      0.50      5159\n",
            "       Music       0.07      0.56      0.12       452\n",
            "     Musical       0.06      0.57      0.11       407\n",
            "     Mystery       0.19      0.74      0.31      3233\n",
            "  Reality-TV       0.00      0.00      0.00         4\n",
            "     Romance       0.39      0.71      0.50      5022\n",
            "      Sci-Fi       0.19      0.79      0.31      2172\n",
            "       Short       0.00      0.00      0.00         0\n",
            "       Sport       0.21      0.76      0.33       482\n",
            "   Talk-Show       0.00      0.00      0.00         1\n",
            "    Thriller       0.33      0.76      0.46      6196\n",
            "         War       0.21      0.84      0.34       916\n",
            "     Western       0.10      0.61      0.17       214\n",
            "\n",
            "   micro avg       0.30      0.71      0.42     70630\n",
            "   macro avg       0.22      0.62      0.30     70630\n",
            "weighted avg       0.36      0.71      0.46     70630\n",
            " samples avg       0.31      0.73      0.42     70630\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/preprocessing/_label.py:909: UserWarning: unknown class(es) ['Adult', 'Game-Show', 'News'] will be ignored\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  movie title - year      genre             expanded-genres  \\\n",
              "0              Son of the Wolf - nan  Adventure                   Adventure   \n",
              "1                   Firstborn - 2003     Action  Action, Adventure, Fantasy   \n",
              "2                  13 Cameras - 2015   Thriller        Crime, Drama, Horror   \n",
              "3  Straight Up, Now Tell Me... - nan    Romance                     Romance   \n",
              "4           The Ugly Duckling - 1959      Crime       Comedy, Crime, Sci-Fi   \n",
              "\n",
              "   rating                                        description  \\\n",
              "0     NaN  Set in 1800'2 Yukon, The Malamute Kid takes on...   \n",
              "1     6.1  Sorcerers fight against themselves for ultimat...   \n",
              "2     5.2  A newlywed couple, move into a new house acros...   \n",
              "3     NaN  When a gay man brings his fiancee home to meet...   \n",
              "4     5.5  Henry Jeckle was always the outsider, a bungli...   \n",
              "\n",
              "                           predicted_genres_baseline  \n",
              "0  (Action, Adventure, Animation, Biography, Hist...  \n",
              "1  (Action, Adventure, Animation, Family, Fantasy...  \n",
              "2  (Comedy, Crime, Horror, Mystery, Romance, Thri...  \n",
              "3          (Comedy, Drama, Family, Musical, Romance)  \n",
              "4  (Biography, Comedy, Drama, Family, Fantasy, Ro...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb6ab4d1-f499-4d5b-a977-e51b7a74e055\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie title - year</th>\n",
              "      <th>genre</th>\n",
              "      <th>expanded-genres</th>\n",
              "      <th>rating</th>\n",
              "      <th>description</th>\n",
              "      <th>predicted_genres_baseline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Son of the Wolf - nan</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Set in 1800'2 Yukon, The Malamute Kid takes on...</td>\n",
              "      <td>(Action, Adventure, Animation, Biography, Hist...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Firstborn - 2003</td>\n",
              "      <td>Action</td>\n",
              "      <td>Action, Adventure, Fantasy</td>\n",
              "      <td>6.1</td>\n",
              "      <td>Sorcerers fight against themselves for ultimat...</td>\n",
              "      <td>(Action, Adventure, Animation, Family, Fantasy...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13 Cameras - 2015</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>Crime, Drama, Horror</td>\n",
              "      <td>5.2</td>\n",
              "      <td>A newlywed couple, move into a new house acros...</td>\n",
              "      <td>(Comedy, Crime, Horror, Mystery, Romance, Thri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Straight Up, Now Tell Me... - nan</td>\n",
              "      <td>Romance</td>\n",
              "      <td>Romance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When a gay man brings his fiancee home to meet...</td>\n",
              "      <td>(Comedy, Drama, Family, Musical, Romance)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Ugly Duckling - 1959</td>\n",
              "      <td>Crime</td>\n",
              "      <td>Comedy, Crime, Sci-Fi</td>\n",
              "      <td>5.5</td>\n",
              "      <td>Henry Jeckle was always the outsider, a bungli...</td>\n",
              "      <td>(Biography, Comedy, Drama, Family, Fantasy, Ro...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb6ab4d1-f499-4d5b-a977-e51b7a74e055')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-fb6ab4d1-f499-4d5b-a977-e51b7a74e055 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-fb6ab4d1-f499-4d5b-a977-e51b7a74e055');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-bef3ab2e-08f6-4acd-8ee1-027fc8048583\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-bef3ab2e-08f6-4acd-8ee1-027fc8048583')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-bef3ab2e-08f6-4acd-8ee1-027fc8048583 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(eval_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"movie title - year\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Firstborn - 2003\",\n          \"The Ugly Duckling - 1959\",\n          \"13 Cameras - 2015\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Action\",\n          \"Crime\",\n          \"Thriller\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expanded-genres\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Action, Adventure, Fantasy\",\n          \"Comedy, Crime, Sci-Fi\",\n          \"Crime, Drama, Horror\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4582575694955837,\n        \"min\": 5.2,\n        \"max\": 6.1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6.1,\n          5.2,\n          5.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Sorcerers fight against themselves for ultimate power and domination of the mortals of earth as the most powerful of them all, a boy, fights for his life, the life of his mother and the people of his village.\",\n          \"Henry Jeckle was always the outsider, a bungling and awkward buffoon, relegated to waiting for his invitation to participate in life that never arrived: until he discovers a medical formula...                See full summary\\u00a0\\u00bb\",\n          \"A newlywed couple, move into a new house across the country, only to find out that their marital issues are the least of their problems. Unbeknownst to them, their grim and lascivious landlord has been spying on them from day one.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_genres_baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          [\n            \"Action\",\n            \"Adventure\",\n            \"Animation\",\n            \"Family\",\n            \"Fantasy\",\n            \"Sci-Fi\"\n          ],\n          [\n            \"Biography\",\n            \"Comedy\",\n            \"Drama\",\n            \"Family\",\n            \"Fantasy\",\n            \"Romance\"\n          ],\n          [\n            \"Comedy\",\n            \"Crime\",\n            \"Horror\",\n            \"Mystery\",\n            \"Romance\",\n            \"Thriller\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "840aa1c6"
      },
      "source": [
        "### 6. LTN Model Definition\n",
        "\n",
        "This cell defines the LTN-enhanced movie classifier.\n",
        "\n",
        "- **Model Definition:**\n",
        "    - An `LTNMovieClassifier` class is defined, which, like the baseline, uses a DistilBERT model for embeddings.\n",
        "    - Instead of a single classifier, it uses a dictionary of `ltn.Predicate` modules, one for each genre. Each predicate is a small neural network that learns a truth value for a movie belonging to a genre.\n",
        "- **Model Instantiation:** The LTN model is instantiated."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(ltn.fuzzy_ops))"
      ],
      "metadata": {
        "id": "F0XysnVrsN7x",
        "outputId": "eeefde45-64ee-4672-b3a2-d2cc2bb3cec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AggregMean', 'AggregMin', 'AggregPMean', 'AggregPMeanError', 'AggregationOperator', 'AndLuk', 'AndMin', 'AndProd', 'BinaryConnectiveOperator', 'ConnectiveOperator', 'Equiv', 'ImpliesGodel', 'ImpliesGoguen', 'ImpliesKleeneDienes', 'ImpliesLuk', 'ImpliesReichenbach', 'LTNObject', 'NotGodel', 'NotStandard', 'OrLuk', 'OrMax', 'OrProbSum', 'SatAgg', 'UnaryConnectiveOperator', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'check_mask', 'check_values', 'eps', 'pi_0', 'pi_1', 'torch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39fb29b4",
        "outputId": "6839bf8b-35de-4a96-def8-30d32a123200"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import ltn  # ltntorch for fuzzy logic\n",
        "from ltn.fuzzy_ops import Equiv, AndLuk, ImpliesLuk, AggregPMean\n",
        "\n",
        "# Label setup\n",
        "ALL_LABELS = list(mlb.classes_)\n",
        "NUM_LABELS = len(ALL_LABELS)\n",
        "LABEL_TO_IDX = {label: i for i, label in enumerate(ALL_LABELS)}\n",
        "\n",
        "# Fuzzy logic operators\n",
        "and_op = AndLuk()\n",
        "imp_op = ImpliesLuk()\n",
        "equiv_op = Equiv(and_op=and_op, implies_op=imp_op)\n",
        "aggregator = AggregPMean(p=2)\n",
        "\n",
        "# Build implication rules\n",
        "implication_pairs = []\n",
        "for _, row in high_confidence_rules.iterrows():\n",
        "    for a in list(row['antecedents']):\n",
        "        for c in list(row['consequents']):\n",
        "            if a in LABEL_TO_IDX and c in LABEL_TO_IDX:\n",
        "                implication_pairs.append((LABEL_TO_IDX[a], LABEL_TO_IDX[c]))\n",
        "implication_pairs = list(set(implication_pairs))\n",
        "print(f\"Loaded {len(implication_pairs)} implication rules from assoc rules.\")\n",
        "\n",
        "# Class imbalance weights\n",
        "pos_counts = y_train.sum(axis=0)\n",
        "neg_counts = y_train.shape[0] - pos_counts\n",
        "epsilon = 1e-5\n",
        "pos_weights = torch.tensor(neg_counts / (pos_counts + epsilon), dtype=torch.float32).to(\"cuda\")\n",
        "\n",
        "# LTN model definition\n",
        "class LTNMultiLabelClassifier(nn.Module):\n",
        "    def __init__(self, transformer_model, num_labels, implication_pairs, pos_weights=None):\n",
        "        super().__init__()\n",
        "        self.transformer = transformer_model\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(transformer_model.config.hidden_size, num_labels)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self.implication_pairs = implication_pairs\n",
        "        self.pos_weights = pos_weights\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embeddings = self.dropout(outputs.last_hidden_state[:, 0, :])\n",
        "        return self.sigmoid(self.fc(embeddings))\n",
        "\n",
        "    def compute_loss(self, pred_truth, true_labels):\n",
        "        eps = 1e-6\n",
        "        pred_clamped = pred_truth.clamp(min=eps, max=1 - eps)\n",
        "\n",
        "        if self.pos_weights is not None:\n",
        "            weights = self.pos_weights.unsqueeze(0).expand_as(true_labels)\n",
        "            bce_loss = -(weights * true_labels * torch.log(pred_clamped) +\n",
        "                         (1 - true_labels) * torch.log(1 - pred_clamped)).mean()\n",
        "        else:\n",
        "            bce_loss = -(true_labels * torch.log(pred_clamped) + (1 - true_labels) * torch.log(1 - pred_clamped)).mean()\n",
        "\n",
        "        equiv_values = equiv_op(pred_truth, true_labels)\n",
        "        sat_gt = aggregator(aggregator(equiv_values))\n",
        "\n",
        "        axiom_values = [imp_op(pred_truth[:, a], pred_truth[:, c]) for a, c in self.implication_pairs]\n",
        "        if axiom_values:\n",
        "            sat_axiom = aggregator(aggregator(torch.stack(axiom_values, dim=1)))\n",
        "        else:\n",
        "            sat_axiom = torch.tensor(1.0, device=pred_truth.device)\n",
        "\n",
        "        logic_loss = 1 - and_op(sat_gt, sat_axiom)\n",
        "        return 0.95 * bce_loss + 0.05 * logic_loss, sat_gt.item(), sat_axiom.item()\n",
        "\n",
        "# Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "transformer = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
        "\n",
        "model = LTNMultiLabelClassifier(transformer, NUM_LABELS, implication_pairs, pos_weights=pos_weights).to(device)\n",
        "\n",
        "# Tokenization\n",
        "X_tok = tokenizer(df['description'].tolist(), padding='max_length', truncation=True,\n",
        "                  max_length=128, return_tensors='pt', return_attention_mask=True)\n",
        "input_ids, attention_mask = X_tok['input_ids'], X_tok['attention_mask']\n",
        "\n",
        "# Train/val split\n",
        "X_train_val_ids, X_test_ids, y_train_val, y_test, X_train_val_mask, X_test_mask = train_test_split(\n",
        "    input_ids, y, attention_mask, test_size=0.2, random_state=42)\n",
        "X_train_ids, X_val_ids, y_train, y_val, X_train_mask, X_val_mask = train_test_split(\n",
        "    X_train_val_ids, y_train_val, X_train_val_mask, test_size=0.125, random_state=42)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(\n",
        "    X_train_ids.to(device), X_train_mask.to(device), torch.tensor(y_train, dtype=torch.float32).to(device))\n",
        "val_dataset = torch.utils.data.TensorDataset(\n",
        "    X_val_ids.to(device), X_val_mask.to(device), torch.tensor(y_val, dtype=torch.float32).to(device))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
        "total_steps = len(train_loader) * 10\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, int(0.1 * total_steps), total_steps)\n",
        "\n",
        "# Training with early stopping\n",
        "best_val_f1 = 0.0\n",
        "patience = 3\n",
        "patience_counter = 0\n",
        "best_model_state = None\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_ids, batch_mask, batch_labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        preds = model(batch_ids, batch_mask)\n",
        "        loss, sat_gt, sat_axiom = model.compute_loss(preds, batch_labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_preds, val_labels = [], []\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_ids, batch_mask, batch_labels in val_loader:\n",
        "            preds = model(batch_ids, batch_mask)\n",
        "            loss, _, _ = model.compute_loss(preds, batch_labels)\n",
        "            val_loss += loss.item()\n",
        "            val_preds.append(preds.cpu().numpy())\n",
        "            val_labels.append(batch_labels.cpu().numpy())\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    y_pred = np.vstack(val_preds)\n",
        "    y_true = np.vstack(val_labels)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    val_f1_micro = f1_score(y_true, y_pred_binary, average='micro', zero_division=0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/10 - Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Micro F1: {val_f1_micro:.4f} | GT Sat: {sat_gt:.4f} | Axiom Sat: {sat_axiom:.4f}\")\n",
        "\n",
        "    if val_f1_micro > best_val_f1:\n",
        "        best_val_f1 = val_f1_micro\n",
        "        best_model_state = model.state_dict()\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "if best_model_state:\n",
        "    model.load_state_dict(best_model_state)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 31 implication rules from assoc rules.\n",
            "Epoch 1/10 - Train Loss: 1.1996 | Val Loss: 0.8389 | Val Micro F1: 0.3691 | GT Sat: 0.6675 | Axiom Sat: 0.9454\n",
            "Epoch 2/10 - Train Loss: 1.0723 | Val Loss: 0.7947 | Val Micro F1: 0.4089 | GT Sat: 0.7345 | Axiom Sat: 0.9404\n",
            "Epoch 3/10 - Train Loss: 1.0969 | Val Loss: 0.8022 | Val Micro F1: 0.3893 | GT Sat: 0.6828 | Axiom Sat: 0.9367\n",
            "Epoch 4/10 - Train Loss: 1.1739 | Val Loss: 0.8075 | Val Micro F1: 0.3942 | GT Sat: 0.7084 | Axiom Sat: 0.9308\n",
            "Epoch 5/10 - Train Loss: 0.9963 | Val Loss: 0.7785 | Val Micro F1: 0.3858 | GT Sat: 0.6678 | Axiom Sat: 0.9393\n",
            "Early stopping at epoch 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. LTN Model Evaluation\n",
        "\n",
        "This cell evaluates the performance of the trained LTN model on the test set.\n",
        "\n",
        "- **Evaluation Mode:** The model is set to evaluation mode using `model.eval()`.\n",
        "- **Prediction:** The model makes predictions on the test data.\n",
        "- **Classification Report:** A classification report is printed, showing precision, recall, and F1-score for each genre."
      ],
      "metadata": {
        "id": "FlEN36-LyCxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from ltn.fuzzy_ops import ImpliesLuk, AggregPMean\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Prepare axiom operators\n",
        "imp_op = ImpliesLuk()\n",
        "aggregator = AggregPMean(p=2)\n",
        "\n",
        "# Test DataLoader with attention_mask\n",
        "test_dataset = TensorDataset(\n",
        "    X_test_ids.to(device),\n",
        "    X_test_mask.to(device),\n",
        "    torch.tensor(y_test, dtype=torch.float32).to(device)\n",
        ")\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Switch to eval mode\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_axioms = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_input_ids, batch_attention_mask, batch_y_true in test_loader:\n",
        "        # Forward pass\n",
        "        logits = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        # Binary predictions\n",
        "        preds = (probs > 0.5).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "        all_labels.append(batch_y_true.cpu().numpy())\n",
        "\n",
        "        # Axiom satisfaction\n",
        "        if hasattr(model, \"implication_pairs\"):\n",
        "            axiom_vals = []\n",
        "            for a_idx, c_idx in model.implication_pairs:\n",
        "                premise = probs[:, a_idx]\n",
        "                conclusion = probs[:, c_idx]\n",
        "                val = imp_op(premise, conclusion)\n",
        "                axiom_vals.append(val)\n",
        "            if axiom_vals:\n",
        "                stacked_axioms = torch.stack(axiom_vals, dim=1)\n",
        "                sat_per_example = aggregator(stacked_axioms)\n",
        "                all_axioms.append(sat_per_example.cpu().numpy())\n",
        "\n",
        "# Concatenate results\n",
        "y_pred_binary = np.vstack(all_preds)\n",
        "y_true = np.vstack(all_labels)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nMulti-label classification report:\")\n",
        "print(classification_report(y_true, y_pred_binary, target_names=mlb.classes_, zero_division=0))\n",
        "\n",
        "# Axiom satisfaction report\n",
        "if all_axioms:\n",
        "    axiom_scores = np.stack(all_axioms)\n",
        "    print(f\"\\nAverage axiom satisfaction on test set: {axiom_scores.mean():.4f}\")\n",
        "    print(f\"Min: {axiom_scores.min():.4f}, Max: {axiom_scores.max():.4f}\")\n",
        "else:\n",
        "    print(\"\\nNo implication rules found in model for axiom satisfaction.\")\n",
        "\n",
        "print(\"\\nAvg predicted labels per sample:\", y_pred_binary.sum(axis=1).mean())\n"
      ],
      "metadata": {
        "id": "S1Dql6eNyEMk",
        "outputId": "0a10b501-13a8-4b18-cb15-015246be82d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multi-label classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Action       0.29      1.00      0.45      1368\n",
            "   Adventure       0.18      1.00      0.30       837\n",
            "   Animation       0.05      1.00      0.10       262\n",
            "   Biography       0.04      1.00      0.07       170\n",
            "      Comedy       0.20      1.00      0.33       934\n",
            "       Crime       0.21      1.00      0.35      1017\n",
            "       Drama       0.39      1.00      0.56      1869\n",
            "      Family       0.07      1.00      0.13       340\n",
            "     Fantasy       0.09      1.00      0.17       437\n",
            "   Film-Noir       0.01      1.00      0.01        32\n",
            "     History       0.04      1.00      0.08       194\n",
            "      Horror       0.18      1.00      0.31       877\n",
            "       Music       0.02      1.00      0.04        88\n",
            "     Musical       0.01      1.00      0.02        48\n",
            "     Mystery       0.11      1.00      0.20       524\n",
            "  Reality-TV       0.00      0.00      0.00         0\n",
            "     Romance       0.16      1.00      0.27       756\n",
            "      Sci-Fi       0.07      1.00      0.13       344\n",
            "       Short       0.00      0.00      0.00         0\n",
            "       Sport       0.01      1.00      0.03        64\n",
            "   Talk-Show       0.00      0.00      0.00         0\n",
            "    Thriller       0.22      1.00      0.36      1045\n",
            "         War       0.03      1.00      0.06       140\n",
            "     Western       0.01      1.00      0.02        41\n",
            "\n",
            "   micro avg       0.10      1.00      0.18     11387\n",
            "   macro avg       0.10      0.88      0.17     11387\n",
            "weighted avg       0.21      1.00      0.33     11387\n",
            " samples avg       0.10      1.00      0.18     11387\n",
            "\n",
            "\n",
            "Average axiom satisfaction on test set: 0.9844\n",
            "Min: 0.9816, Max: 0.9867\n",
            "\n",
            "Avg predicted labels per sample: 24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bf79f81"
      },
      "source": [
        "### 9. Model Performance Comparison\n",
        "\n",
        "This cell provides a summary and comparison of the performance of both the baseline and the LTN-enhanced models. It discusses the poor performance of both models and suggests potential reasons and next steps for improvement."
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MTFP_UVaaugH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}