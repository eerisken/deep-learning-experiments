{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a7ac28948fff4f13bc12317829521c0b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9a37fcc739534ffca31cd7fef7c8f87d",
              "IPY_MODEL_28ccc756df24410e95cbc85d5842dd2a",
              "IPY_MODEL_2d1476c0c19b4728b9d876446c0e67ff"
            ],
            "layout": "IPY_MODEL_25100dda4c264b22aed4c453924790c7"
          }
        },
        "9a37fcc739534ffca31cd7fef7c8f87d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8f48e8f3d3f142c084172ee12bcc6d67",
            "placeholder": "​",
            "style": "IPY_MODEL_fad27b1d83cc4488b5b181087a71bd08",
            "value": "model.safetensors: 100%"
          }
        },
        "28ccc756df24410e95cbc85d5842dd2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c754333daa534e328f73542ba6742753",
            "max": 267954768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a07bd3ae5ade4833ab2fef0ba3e31e1c",
            "value": 267954768
          }
        },
        "2d1476c0c19b4728b9d876446c0e67ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_38e3d6b92f5a4fae9c029599fb7905bc",
            "placeholder": "​",
            "style": "IPY_MODEL_501181774d6749549479f44340bf37d3",
            "value": " 268M/268M [00:05&lt;00:00, 47.8MB/s]"
          }
        },
        "25100dda4c264b22aed4c453924790c7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f48e8f3d3f142c084172ee12bcc6d67": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fad27b1d83cc4488b5b181087a71bd08": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c754333daa534e328f73542ba6742753": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a07bd3ae5ade4833ab2fef0ba3e31e1c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "38e3d6b92f5a4fae9c029599fb7905bc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "501181774d6749549479f44340bf37d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01bcf10c"
      },
      "source": [
        "### 1. Data Loading and Preprocessing\n",
        "\n",
        "This cell handles the initial setup, including mounting Google Drive, loading the dataset, and performing essential preprocessing steps.\n",
        "\n",
        "- **Drive Mount:** Mounts the Google Drive to access the dataset file.\n",
        "- **Data Loading:** Loads the movie data from a CSV file into a pandas DataFrame.\n",
        "- **Association Rule Mining:**\n",
        "    - The `Output` column, containing comma-separated genres, is split into a list of genres for each movie.\n",
        "    - `TransactionEncoder` converts this list into a one-hot encoded format suitable for association rule mining.\n",
        "    - `fpgrowth` is used to find frequent itemsets of genres.\n",
        "    - `association_rules` generates rules based on these itemsets, which are then filtered for high confidence and support.\n",
        "- **Multi-Label Classification Preprocessing:**\n",
        "    - The `description` for each movie is extracted from the `Input` column.\n",
        "    - The `Output` column is converted into a list of genre labels.\n",
        "    - `MultiLabelBinarizer` transforms these genre lists into a binary matrix format, which is the standard for multi-label classification tasks."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlxtend\n",
        "!pip install ltntorch"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zRP__THJNFjt",
        "outputId": "7dfe8af4-1547-4b38-92e1-4f5c14e12223"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mlxtend in /usr/local/lib/python3.11/dist-packages (0.23.4)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.16.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.0.2)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.6.1)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (3.10.0)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /usr/local/lib/python3.11/dist-packages (from mlxtend) (1.5.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (4.59.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (25.0)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=3.0.0->mlxtend) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=0.24.2->mlxtend) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn>=1.3.1->mlxtend) (3.6.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.17.0)\n",
            "Collecting ltntorch\n",
            "  Downloading LTNtorch-1.0.2-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from ltntorch) (2.0.2)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (from ltntorch) (2.6.0+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (4.14.1)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (3.5)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (2025.3.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->ltntorch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->ltntorch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->ltntorch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->ltntorch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->ltntorch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->ltntorch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->ltntorch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->ltntorch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->ltntorch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (0.6.2)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch->ltntorch)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->ltntorch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch->ltntorch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch->ltntorch) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch->ltntorch) (3.0.2)\n",
            "Downloading LTNtorch-1.0.2-py3-none-any.whl (29 kB)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m76.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12, ltntorch\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.23.4\n",
            "    Uninstalling nvidia-nccl-cu12-2.23.4:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.23.4\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed ltntorch-1.0.2 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2afdf29e",
        "outputId": "a2f7569b-1995-4957-b8ea-db774b17aac1"
      },
      "source": [
        "from google.colab import drive\n",
        "import pandas as pd\n",
        "from collections import Counter\n",
        "from mlxtend.preprocessing import TransactionEncoder\n",
        "from mlxtend.frequent_patterns import fpgrowth, association_rules\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/My Drive/movie-genre-prediction/train.csv')\n",
        "\n",
        "# --- Step 1: Parse genre labels ---\n",
        "# Assumes genres are comma-separated strings\n",
        "df[\"genre_list\"] = df[\"expanded-genres\"].fillna(\"\").apply(lambda x: [genre.strip() for genre in x.split(\", \") if genre.strip()])\n",
        "\n",
        "# --- Step 2: Count frequency of each genre ---\n",
        "genre_counter = Counter()\n",
        "for genres in df[\"genre_list\"]:\n",
        "    genre_counter.update(genres)\n",
        "\n",
        "# Display number of samples per genre\n",
        "print(\"Samples per genre:\")\n",
        "for genre, count in genre_counter.items():\n",
        "    print(f\"{genre:<15} {count}\")\n",
        "\n",
        "# --- Step 3: Identify minority genres ---\n",
        "# Set threshold for minority genre (e.g., fewer than 200 samples)\n",
        "MINORITY_THRESHOLD = 200\n",
        "minority_genres = {genre for genre, count in genre_counter.items() if count < MINORITY_THRESHOLD}\n",
        "\n",
        "print(f\"\\nMinority genres (< {MINORITY_THRESHOLD} samples): {sorted(minority_genres)}\")\n",
        "\n",
        "# --- Step 4: Split dataset ---\n",
        "# Mark rows that contain any minority genre\n",
        "df[\"contains_minority\"] = df[\"genre_list\"].apply(lambda genres: any(g in minority_genres for g in genres))\n",
        "\n",
        "# Keep all minority rows\n",
        "minority_df = df[df[\"contains_minority\"]]\n",
        "\n",
        "# Sample 10% of the remaining data\n",
        "non_minority_df = df[~df[\"contains_minority\"]].sample(frac=0.10, random_state=42)\n",
        "\n",
        "print(f\"\\nOriginal dataset size: {len(df)}\")\n",
        "# Combine both\n",
        "df = pd.concat([minority_df, non_minority_df]).reset_index(drop=True)\n",
        "\n",
        "print(f\"Minority rows kept: {len(minority_df)}\")\n",
        "print(f\"Non-minority rows sampled: {len(non_minority_df)}\")\n",
        "print(f\"Total train set size: {len(df)}\")\n",
        "\n",
        "# Association rule mining\n",
        "transactions = df['expanded-genres'].str.split(', ').tolist()\n",
        "te = TransactionEncoder()\n",
        "te_ary = te.fit(transactions).transform(transactions)\n",
        "df_encoded = pd.DataFrame(te_ary, columns=te.columns_)\n",
        "frequent_itemsets = fpgrowth(df_encoded, min_support=0.01, use_colnames=True)\n",
        "rules = association_rules(frequent_itemsets, metric=\"lift\", min_threshold=1)\n",
        "high_confidence_rules = rules[(rules['confidence'] > 0.25) & (rules['support'] > 0.001)]\n",
        "\n",
        "# Data preprocessing for multi-label classification\n",
        "#df['description'] = df['Input'].apply(lambda x: x.split('\\n\\n', 1)[1] if '\\n\\n' in x else '')\n",
        "df['Output-Label'] = df['expanded-genres'].str.split(', ')\n",
        "mlb = MultiLabelBinarizer()\n",
        "y = mlb.fit_transform(df['Output-Label'])\n",
        "\n",
        "# Display results\n",
        "display(df.head())\n",
        "display(high_confidence_rules)\n",
        "print(\"Descriptions:\")\n",
        "display(df['description'].head())\n",
        "print(\"\\nBinary Labels (y):\")\n",
        "display(y[:5])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n",
            "Samples per genre:\n",
            "Fantasy         20868\n",
            "Sci-Fi          17567\n",
            "Comedy          46119\n",
            "Drama           96184\n",
            "Romance         39076\n",
            "Thriller        50464\n",
            "Animation       13018\n",
            "Adventure       41307\n",
            "Family          17086\n",
            "Biography       9489\n",
            "Action          67419\n",
            "Horror          41873\n",
            "Mystery         25737\n",
            "Musical         3288\n",
            "Music           3653\n",
            "History         9576\n",
            "Crime           48370\n",
            "War             7359\n",
            "Film-Noir       2066\n",
            "Western         1632\n",
            "Sport           3518\n",
            "Game-Show       6\n",
            "Reality-TV      22\n",
            "Adult           4\n",
            "News            16\n",
            "Talk-Show       4\n",
            "Short           1\n",
            "\n",
            "Minority genres (< 200 samples): ['Adult', 'Game-Show', 'News', 'Reality-TV', 'Short', 'Talk-Show']\n",
            "\n",
            "Original dataset size: 238256\n",
            "Minority rows kept: 51\n",
            "Non-minority rows sampled: 23820\n",
            "Total train set size: 23871\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "           movie title - year     genre            expanded-genres  rating  \\\n",
              "0          Outrageous! - 1998    Family          Family, Game-Show     NaN   \n",
              "1  Vancouver Remembers - 2018       War   History, Reality-TV, War     NaN   \n",
              "2         Cocaine Wars - 1985    Action       Action, Adult, Drama     4.3   \n",
              "3             Affected - 2010  Thriller      Drama, News, Thriller     NaN   \n",
              "4           Oh, Youth! - 1995   Romance  Comedy, Drama, Reality-TV     5.4   \n",
              "\n",
              "                                         description  \\\n",
              "0  Two teams try to entice unsuspecting people to...   \n",
              "1  The coverage of the day's Remembrance Day cere...   \n",
              "2  A DEA undercover agent who works for the bigge...   \n",
              "3  Natural resources are running out and a myster...   \n",
              "4  A North Korean romantic comedy that involves m...   \n",
              "\n",
              "                    genre_list  contains_minority                 Output-Label  \n",
              "0          [Family, Game-Show]               True          [Family, Game-Show]  \n",
              "1   [History, Reality-TV, War]               True   [History, Reality-TV, War]  \n",
              "2       [Action, Adult, Drama]               True       [Action, Adult, Drama]  \n",
              "3      [Drama, News, Thriller]               True      [Drama, News, Thriller]  \n",
              "4  [Comedy, Drama, Reality-TV]               True  [Comedy, Drama, Reality-TV]  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c489fd49-0fbc-4665-acc6-ec814e3dbe03\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie title - year</th>\n",
              "      <th>genre</th>\n",
              "      <th>expanded-genres</th>\n",
              "      <th>rating</th>\n",
              "      <th>description</th>\n",
              "      <th>genre_list</th>\n",
              "      <th>contains_minority</th>\n",
              "      <th>Output-Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Outrageous! - 1998</td>\n",
              "      <td>Family</td>\n",
              "      <td>Family, Game-Show</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Two teams try to entice unsuspecting people to...</td>\n",
              "      <td>[Family, Game-Show]</td>\n",
              "      <td>True</td>\n",
              "      <td>[Family, Game-Show]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Vancouver Remembers - 2018</td>\n",
              "      <td>War</td>\n",
              "      <td>History, Reality-TV, War</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The coverage of the day's Remembrance Day cere...</td>\n",
              "      <td>[History, Reality-TV, War]</td>\n",
              "      <td>True</td>\n",
              "      <td>[History, Reality-TV, War]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Cocaine Wars - 1985</td>\n",
              "      <td>Action</td>\n",
              "      <td>Action, Adult, Drama</td>\n",
              "      <td>4.3</td>\n",
              "      <td>A DEA undercover agent who works for the bigge...</td>\n",
              "      <td>[Action, Adult, Drama]</td>\n",
              "      <td>True</td>\n",
              "      <td>[Action, Adult, Drama]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Affected - 2010</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>Drama, News, Thriller</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Natural resources are running out and a myster...</td>\n",
              "      <td>[Drama, News, Thriller]</td>\n",
              "      <td>True</td>\n",
              "      <td>[Drama, News, Thriller]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Oh, Youth! - 1995</td>\n",
              "      <td>Romance</td>\n",
              "      <td>Comedy, Drama, Reality-TV</td>\n",
              "      <td>5.4</td>\n",
              "      <td>A North Korean romantic comedy that involves m...</td>\n",
              "      <td>[Comedy, Drama, Reality-TV]</td>\n",
              "      <td>True</td>\n",
              "      <td>[Comedy, Drama, Reality-TV]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c489fd49-0fbc-4665-acc6-ec814e3dbe03')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-c489fd49-0fbc-4665-acc6-ec814e3dbe03 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-c489fd49-0fbc-4665-acc6-ec814e3dbe03');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-ec427f4a-dafa-4ad9-bddd-64551079f0ba\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-ec427f4a-dafa-4ad9-bddd-64551079f0ba')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-ec427f4a-dafa-4ad9-bddd-64551079f0ba button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(y[:5])\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"movie title - year\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Vancouver Remembers - 2018\",\n          \"Oh, Youth! - 1995\",\n          \"Cocaine Wars - 1985\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"War\",\n          \"Romance\",\n          \"Action\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expanded-genres\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"History, Reality-TV, War\",\n          \"Comedy, Drama, Reality-TV\",\n          \"Action, Adult, Drama\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.7778174593052027,\n        \"min\": 4.3,\n        \"max\": 5.4,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          5.4,\n          4.3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"The coverage of the day's Remembrance Day ceremonies at Victory Square and in Victoria.\",\n          \"A North Korean romantic comedy that involves martial arts.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre_list\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contains_minority\",\n      \"properties\": {\n        \"dtype\": \"boolean\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          true\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Output-Label\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "               antecedents  consequents  antecedent support  \\\n",
              "0                 (Family)  (Adventure)            0.070546   \n",
              "3                 (Family)     (Comedy)            0.070546   \n",
              "5                (History)      (Drama)            0.037577   \n",
              "6                    (War)      (Drama)            0.028612   \n",
              "9          (Comedy, Crime)     (Action)            0.033053   \n",
              "12              (Thriller)     (Horror)            0.211638   \n",
              "13                (Horror)   (Thriller)            0.178250   \n",
              "18                (Sci-Fi)     (Action)            0.074777   \n",
              "20                 (Drama)      (Crime)            0.400276   \n",
              "21                 (Crime)      (Drama)            0.207574   \n",
              "22                (Action)      (Crime)            0.283314   \n",
              "23                 (Crime)     (Action)            0.207574   \n",
              "26         (Drama, Action)      (Crime)            0.093335   \n",
              "27         (Action, Crime)      (Drama)            0.073520   \n",
              "30      (Action, Thriller)      (Crime)            0.043400   \n",
              "35             (Biography)      (Drama)            0.039127   \n",
              "37             (Animation)     (Action)            0.055172   \n",
              "38             (Animation)  (Adventure)            0.055172   \n",
              "43             (Animation)     (Comedy)            0.055172   \n",
              "44     (Action, Animation)  (Adventure)            0.016882   \n",
              "46  (Animation, Adventure)     (Action)            0.028696   \n",
              "51               (Romance)      (Drama)            0.163671   \n",
              "52                (Comedy)    (Romance)            0.196556   \n",
              "53               (Romance)     (Comedy)            0.163671   \n",
              "54         (Comedy, Drama)    (Romance)            0.051192   \n",
              "58                (Action)  (Adventure)            0.283314   \n",
              "59             (Adventure)     (Action)            0.173432   \n",
              "60      (Drama, Adventure)     (Action)            0.044992   \n",
              "62        (Comedy, Action)  (Adventure)            0.044280   \n",
              "63     (Comedy, Adventure)     (Action)            0.040970   \n",
              "73               (Mystery)   (Thriller)            0.107453   \n",
              "75               (Mystery)      (Drama)            0.107453   \n",
              "76               (Mystery)      (Crime)            0.107453   \n",
              "78               (Mystery)     (Horror)            0.107453   \n",
              "80     (Mystery, Thriller)     (Horror)            0.033220   \n",
              "82       (Mystery, Horror)   (Thriller)            0.033555   \n",
              "86        (Drama, Mystery)      (Crime)            0.044322   \n",
              "88        (Mystery, Crime)      (Drama)            0.030581   \n",
              "\n",
              "    consequent support   support  confidence      lift  representativity  \\\n",
              "0             0.173432  0.020653    0.292755  1.688010               1.0   \n",
              "3             0.196556  0.020904    0.296318  1.507548               1.0   \n",
              "5             0.400276  0.025386    0.675585  1.687797               1.0   \n",
              "6             0.400276  0.018558    0.648609  1.620403               1.0   \n",
              "9             0.283314  0.010054    0.304183  1.073657               1.0   \n",
              "12            0.178250  0.056135    0.265241  1.488033               1.0   \n",
              "13            0.211638  0.056135    0.314924  1.488033               1.0   \n",
              "18            0.283314  0.021574    0.288515  1.018357               1.0   \n",
              "20            0.207574  0.107620    0.268864  1.295270               1.0   \n",
              "21            0.400276  0.107620    0.518466  1.295270               1.0   \n",
              "22            0.207574  0.073520    0.259500  1.250157               1.0   \n",
              "23            0.283314  0.073520    0.354188  1.250157               1.0   \n",
              "26            0.207574  0.029618    0.317325  1.528731               1.0   \n",
              "27            0.400276  0.029618    0.402849  1.006427               1.0   \n",
              "30            0.207574  0.011730    0.270270  1.302043               1.0   \n",
              "35            0.400276  0.025303    0.646681  1.615586               1.0   \n",
              "37            0.283314  0.016882    0.305998  1.080067               1.0   \n",
              "38            0.173432  0.028696    0.520121  2.998990               1.0   \n",
              "43            0.196556  0.016212    0.293850  1.494988               1.0   \n",
              "44            0.173432  0.010641    0.630273  3.634117               1.0   \n",
              "46            0.283314  0.010641    0.370803  1.308803               1.0   \n",
              "51            0.400276  0.091617    0.559765  1.398445               1.0   \n",
              "52            0.163671  0.053286    0.271100  1.656366               1.0   \n",
              "53            0.196556  0.053286    0.325569  1.656366               1.0   \n",
              "54            0.163671  0.016505    0.322422  1.969936               1.0   \n",
              "58            0.173432  0.079553    0.280793  1.619034               1.0   \n",
              "59            0.283314  0.079553    0.458696  1.619034               1.0   \n",
              "60            0.283314  0.015668    0.348231  1.229132               1.0   \n",
              "62            0.173432  0.012568    0.283822  1.636502               1.0   \n",
              "63            0.283314  0.012568    0.306748  1.082714               1.0   \n",
              "73            0.211638  0.033220    0.309162  1.460808               1.0   \n",
              "75            0.400276  0.044322    0.412476  1.030477               1.0   \n",
              "76            0.207574  0.030581    0.284600  1.371079               1.0   \n",
              "78            0.178250  0.033555    0.312281  1.751928               1.0   \n",
              "80            0.178250  0.012400    0.373266  2.094062               1.0   \n",
              "82            0.211638  0.012400    0.369538  1.746089               1.0   \n",
              "86            0.207574  0.013238    0.298677  1.438893               1.0   \n",
              "88            0.400276  0.013238    0.432877  1.081444               1.0   \n",
              "\n",
              "    leverage  conviction  zhangs_metric   jaccard  certainty  kulczynski  \n",
              "0   0.008418    1.168716       0.438523  0.092478   0.144360    0.205919  \n",
              "3   0.007038    1.141771       0.362225  0.084907   0.124168    0.201335  \n",
              "5   0.010345    1.848632       0.423422  0.061548   0.459060    0.369504  \n",
              "6   0.007105    1.706713       0.394147  0.045227   0.414078    0.347486  \n",
              "9   0.000690    1.029991       0.070949  0.032823   0.029117    0.169835  \n",
              "12  0.018411    1.118395       0.416017  0.168194   0.105862    0.290083  \n",
              "13  0.018411    1.150766       0.399114  0.168194   0.131013    0.290083  \n",
              "18  0.000389    1.007310       0.019483  0.064111   0.007257    0.182333  \n",
              "20  0.024533    1.083829       0.380109  0.215141   0.077345    0.393665  \n",
              "21  0.024533    1.245444       0.287674  0.215141   0.197074    0.393665  \n",
              "22  0.014711    1.070123       0.279203  0.176152   0.065528    0.306844  \n",
              "23  0.014711    1.109743       0.252517  0.176152   0.098890    0.306844  \n",
              "26  0.010244    1.160766       0.381467  0.109172   0.138500    0.230005  \n",
              "27  0.000189    1.004308       0.006893  0.066679   0.004290    0.238421  \n",
              "30  0.002721    1.085917       0.242501  0.049028   0.079119    0.163389  \n",
              "35  0.009641    1.697399       0.396545  0.061103   0.410863    0.354947  \n",
              "37  0.001252    1.032686       0.078460  0.052494   0.031651    0.182794  \n",
              "38  0.019127    1.722452       0.705477  0.143546   0.419432    0.342790  \n",
              "43  0.005368    1.137780       0.350432  0.068837   0.121095    0.188165  \n",
              "44  0.007713    2.235616       0.737277  0.059221   0.552696    0.345813  \n",
              "46  0.002511    1.139048       0.242914  0.035307   0.122074    0.204180  \n",
              "51  0.026104    1.362279       0.340679  0.193969   0.265936    0.394325  \n",
              "52  0.021116    1.147384       0.493213  0.173604   0.128452    0.298335  \n",
              "53  0.021116    1.191292       0.473819  0.173604   0.160575    0.298335  \n",
              "54  0.008127    1.234292       0.518935  0.083210   0.189819    0.211633  \n",
              "58  0.030417    1.149276       0.533494  0.210906   0.129887    0.369744  \n",
              "59  0.030417    1.323997       0.462573  0.210906   0.244711    0.369744  \n",
              "60  0.002921    1.099600       0.195200  0.050114   0.090579    0.201766  \n",
              "62  0.004888    1.154138       0.406961  0.061262   0.133552    0.178143  \n",
              "63  0.000960    1.033803       0.079658  0.040317   0.032698    0.175554  \n",
              "73  0.010479    1.141168       0.353424  0.116208   0.123705    0.233065  \n",
              "75  0.001311    1.020764       0.033136  0.095643   0.020341    0.261602  \n",
              "76  0.008277    1.107669       0.303230  0.107511   0.097203    0.215963  \n",
              "78  0.014402    1.194892       0.480871  0.133079   0.163104    0.250265  \n",
              "80  0.006478    1.311163       0.540412  0.062290   0.237318    0.221416  \n",
              "82  0.005298    1.250452       0.442127  0.053266   0.200289    0.214064  \n",
              "86  0.004038    1.129901       0.319167  0.055468   0.114967    0.181225  \n",
              "88  0.000997    1.057483       0.077686  0.031698   0.054359    0.232974  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-27d7c3b2-047f-4a87-8bf3-e7e5661b12c7\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>antecedents</th>\n",
              "      <th>consequents</th>\n",
              "      <th>antecedent support</th>\n",
              "      <th>consequent support</th>\n",
              "      <th>support</th>\n",
              "      <th>confidence</th>\n",
              "      <th>lift</th>\n",
              "      <th>representativity</th>\n",
              "      <th>leverage</th>\n",
              "      <th>conviction</th>\n",
              "      <th>zhangs_metric</th>\n",
              "      <th>jaccard</th>\n",
              "      <th>certainty</th>\n",
              "      <th>kulczynski</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>(Family)</td>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>0.070546</td>\n",
              "      <td>0.173432</td>\n",
              "      <td>0.020653</td>\n",
              "      <td>0.292755</td>\n",
              "      <td>1.688010</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.008418</td>\n",
              "      <td>1.168716</td>\n",
              "      <td>0.438523</td>\n",
              "      <td>0.092478</td>\n",
              "      <td>0.144360</td>\n",
              "      <td>0.205919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>(Family)</td>\n",
              "      <td>(Comedy)</td>\n",
              "      <td>0.070546</td>\n",
              "      <td>0.196556</td>\n",
              "      <td>0.020904</td>\n",
              "      <td>0.296318</td>\n",
              "      <td>1.507548</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007038</td>\n",
              "      <td>1.141771</td>\n",
              "      <td>0.362225</td>\n",
              "      <td>0.084907</td>\n",
              "      <td>0.124168</td>\n",
              "      <td>0.201335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>(History)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.037577</td>\n",
              "      <td>0.400276</td>\n",
              "      <td>0.025386</td>\n",
              "      <td>0.675585</td>\n",
              "      <td>1.687797</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010345</td>\n",
              "      <td>1.848632</td>\n",
              "      <td>0.423422</td>\n",
              "      <td>0.061548</td>\n",
              "      <td>0.459060</td>\n",
              "      <td>0.369504</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>(War)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.028612</td>\n",
              "      <td>0.400276</td>\n",
              "      <td>0.018558</td>\n",
              "      <td>0.648609</td>\n",
              "      <td>1.620403</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007105</td>\n",
              "      <td>1.706713</td>\n",
              "      <td>0.394147</td>\n",
              "      <td>0.045227</td>\n",
              "      <td>0.414078</td>\n",
              "      <td>0.347486</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>(Comedy, Crime)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.033053</td>\n",
              "      <td>0.283314</td>\n",
              "      <td>0.010054</td>\n",
              "      <td>0.304183</td>\n",
              "      <td>1.073657</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000690</td>\n",
              "      <td>1.029991</td>\n",
              "      <td>0.070949</td>\n",
              "      <td>0.032823</td>\n",
              "      <td>0.029117</td>\n",
              "      <td>0.169835</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>(Thriller)</td>\n",
              "      <td>(Horror)</td>\n",
              "      <td>0.211638</td>\n",
              "      <td>0.178250</td>\n",
              "      <td>0.056135</td>\n",
              "      <td>0.265241</td>\n",
              "      <td>1.488033</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.018411</td>\n",
              "      <td>1.118395</td>\n",
              "      <td>0.416017</td>\n",
              "      <td>0.168194</td>\n",
              "      <td>0.105862</td>\n",
              "      <td>0.290083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>(Horror)</td>\n",
              "      <td>(Thriller)</td>\n",
              "      <td>0.178250</td>\n",
              "      <td>0.211638</td>\n",
              "      <td>0.056135</td>\n",
              "      <td>0.314924</td>\n",
              "      <td>1.488033</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.018411</td>\n",
              "      <td>1.150766</td>\n",
              "      <td>0.399114</td>\n",
              "      <td>0.168194</td>\n",
              "      <td>0.131013</td>\n",
              "      <td>0.290083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>(Sci-Fi)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.074777</td>\n",
              "      <td>0.283314</td>\n",
              "      <td>0.021574</td>\n",
              "      <td>0.288515</td>\n",
              "      <td>1.018357</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000389</td>\n",
              "      <td>1.007310</td>\n",
              "      <td>0.019483</td>\n",
              "      <td>0.064111</td>\n",
              "      <td>0.007257</td>\n",
              "      <td>0.182333</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>(Drama)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.400276</td>\n",
              "      <td>0.207574</td>\n",
              "      <td>0.107620</td>\n",
              "      <td>0.268864</td>\n",
              "      <td>1.295270</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.024533</td>\n",
              "      <td>1.083829</td>\n",
              "      <td>0.380109</td>\n",
              "      <td>0.215141</td>\n",
              "      <td>0.077345</td>\n",
              "      <td>0.393665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>(Crime)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.207574</td>\n",
              "      <td>0.400276</td>\n",
              "      <td>0.107620</td>\n",
              "      <td>0.518466</td>\n",
              "      <td>1.295270</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.024533</td>\n",
              "      <td>1.245444</td>\n",
              "      <td>0.287674</td>\n",
              "      <td>0.215141</td>\n",
              "      <td>0.197074</td>\n",
              "      <td>0.393665</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>(Action)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.283314</td>\n",
              "      <td>0.207574</td>\n",
              "      <td>0.073520</td>\n",
              "      <td>0.259500</td>\n",
              "      <td>1.250157</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.014711</td>\n",
              "      <td>1.070123</td>\n",
              "      <td>0.279203</td>\n",
              "      <td>0.176152</td>\n",
              "      <td>0.065528</td>\n",
              "      <td>0.306844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>(Crime)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.207574</td>\n",
              "      <td>0.283314</td>\n",
              "      <td>0.073520</td>\n",
              "      <td>0.354188</td>\n",
              "      <td>1.250157</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.014711</td>\n",
              "      <td>1.109743</td>\n",
              "      <td>0.252517</td>\n",
              "      <td>0.176152</td>\n",
              "      <td>0.098890</td>\n",
              "      <td>0.306844</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>(Drama, Action)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.093335</td>\n",
              "      <td>0.207574</td>\n",
              "      <td>0.029618</td>\n",
              "      <td>0.317325</td>\n",
              "      <td>1.528731</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010244</td>\n",
              "      <td>1.160766</td>\n",
              "      <td>0.381467</td>\n",
              "      <td>0.109172</td>\n",
              "      <td>0.138500</td>\n",
              "      <td>0.230005</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>(Action, Crime)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.073520</td>\n",
              "      <td>0.400276</td>\n",
              "      <td>0.029618</td>\n",
              "      <td>0.402849</td>\n",
              "      <td>1.006427</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000189</td>\n",
              "      <td>1.004308</td>\n",
              "      <td>0.006893</td>\n",
              "      <td>0.066679</td>\n",
              "      <td>0.004290</td>\n",
              "      <td>0.238421</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>(Action, Thriller)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.043400</td>\n",
              "      <td>0.207574</td>\n",
              "      <td>0.011730</td>\n",
              "      <td>0.270270</td>\n",
              "      <td>1.302043</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.002721</td>\n",
              "      <td>1.085917</td>\n",
              "      <td>0.242501</td>\n",
              "      <td>0.049028</td>\n",
              "      <td>0.079119</td>\n",
              "      <td>0.163389</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>(Biography)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.039127</td>\n",
              "      <td>0.400276</td>\n",
              "      <td>0.025303</td>\n",
              "      <td>0.646681</td>\n",
              "      <td>1.615586</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.009641</td>\n",
              "      <td>1.697399</td>\n",
              "      <td>0.396545</td>\n",
              "      <td>0.061103</td>\n",
              "      <td>0.410863</td>\n",
              "      <td>0.354947</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>(Animation)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.055172</td>\n",
              "      <td>0.283314</td>\n",
              "      <td>0.016882</td>\n",
              "      <td>0.305998</td>\n",
              "      <td>1.080067</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001252</td>\n",
              "      <td>1.032686</td>\n",
              "      <td>0.078460</td>\n",
              "      <td>0.052494</td>\n",
              "      <td>0.031651</td>\n",
              "      <td>0.182794</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>(Animation)</td>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>0.055172</td>\n",
              "      <td>0.173432</td>\n",
              "      <td>0.028696</td>\n",
              "      <td>0.520121</td>\n",
              "      <td>2.998990</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.019127</td>\n",
              "      <td>1.722452</td>\n",
              "      <td>0.705477</td>\n",
              "      <td>0.143546</td>\n",
              "      <td>0.419432</td>\n",
              "      <td>0.342790</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>(Animation)</td>\n",
              "      <td>(Comedy)</td>\n",
              "      <td>0.055172</td>\n",
              "      <td>0.196556</td>\n",
              "      <td>0.016212</td>\n",
              "      <td>0.293850</td>\n",
              "      <td>1.494988</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.005368</td>\n",
              "      <td>1.137780</td>\n",
              "      <td>0.350432</td>\n",
              "      <td>0.068837</td>\n",
              "      <td>0.121095</td>\n",
              "      <td>0.188165</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>(Action, Animation)</td>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>0.016882</td>\n",
              "      <td>0.173432</td>\n",
              "      <td>0.010641</td>\n",
              "      <td>0.630273</td>\n",
              "      <td>3.634117</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.007713</td>\n",
              "      <td>2.235616</td>\n",
              "      <td>0.737277</td>\n",
              "      <td>0.059221</td>\n",
              "      <td>0.552696</td>\n",
              "      <td>0.345813</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>(Animation, Adventure)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.028696</td>\n",
              "      <td>0.283314</td>\n",
              "      <td>0.010641</td>\n",
              "      <td>0.370803</td>\n",
              "      <td>1.308803</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.002511</td>\n",
              "      <td>1.139048</td>\n",
              "      <td>0.242914</td>\n",
              "      <td>0.035307</td>\n",
              "      <td>0.122074</td>\n",
              "      <td>0.204180</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>(Romance)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.163671</td>\n",
              "      <td>0.400276</td>\n",
              "      <td>0.091617</td>\n",
              "      <td>0.559765</td>\n",
              "      <td>1.398445</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.026104</td>\n",
              "      <td>1.362279</td>\n",
              "      <td>0.340679</td>\n",
              "      <td>0.193969</td>\n",
              "      <td>0.265936</td>\n",
              "      <td>0.394325</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>(Comedy)</td>\n",
              "      <td>(Romance)</td>\n",
              "      <td>0.196556</td>\n",
              "      <td>0.163671</td>\n",
              "      <td>0.053286</td>\n",
              "      <td>0.271100</td>\n",
              "      <td>1.656366</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.021116</td>\n",
              "      <td>1.147384</td>\n",
              "      <td>0.493213</td>\n",
              "      <td>0.173604</td>\n",
              "      <td>0.128452</td>\n",
              "      <td>0.298335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>(Romance)</td>\n",
              "      <td>(Comedy)</td>\n",
              "      <td>0.163671</td>\n",
              "      <td>0.196556</td>\n",
              "      <td>0.053286</td>\n",
              "      <td>0.325569</td>\n",
              "      <td>1.656366</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.021116</td>\n",
              "      <td>1.191292</td>\n",
              "      <td>0.473819</td>\n",
              "      <td>0.173604</td>\n",
              "      <td>0.160575</td>\n",
              "      <td>0.298335</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>(Comedy, Drama)</td>\n",
              "      <td>(Romance)</td>\n",
              "      <td>0.051192</td>\n",
              "      <td>0.163671</td>\n",
              "      <td>0.016505</td>\n",
              "      <td>0.322422</td>\n",
              "      <td>1.969936</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.008127</td>\n",
              "      <td>1.234292</td>\n",
              "      <td>0.518935</td>\n",
              "      <td>0.083210</td>\n",
              "      <td>0.189819</td>\n",
              "      <td>0.211633</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>(Action)</td>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>0.283314</td>\n",
              "      <td>0.173432</td>\n",
              "      <td>0.079553</td>\n",
              "      <td>0.280793</td>\n",
              "      <td>1.619034</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.030417</td>\n",
              "      <td>1.149276</td>\n",
              "      <td>0.533494</td>\n",
              "      <td>0.210906</td>\n",
              "      <td>0.129887</td>\n",
              "      <td>0.369744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.173432</td>\n",
              "      <td>0.283314</td>\n",
              "      <td>0.079553</td>\n",
              "      <td>0.458696</td>\n",
              "      <td>1.619034</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.030417</td>\n",
              "      <td>1.323997</td>\n",
              "      <td>0.462573</td>\n",
              "      <td>0.210906</td>\n",
              "      <td>0.244711</td>\n",
              "      <td>0.369744</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>(Drama, Adventure)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.044992</td>\n",
              "      <td>0.283314</td>\n",
              "      <td>0.015668</td>\n",
              "      <td>0.348231</td>\n",
              "      <td>1.229132</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.002921</td>\n",
              "      <td>1.099600</td>\n",
              "      <td>0.195200</td>\n",
              "      <td>0.050114</td>\n",
              "      <td>0.090579</td>\n",
              "      <td>0.201766</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>(Comedy, Action)</td>\n",
              "      <td>(Adventure)</td>\n",
              "      <td>0.044280</td>\n",
              "      <td>0.173432</td>\n",
              "      <td>0.012568</td>\n",
              "      <td>0.283822</td>\n",
              "      <td>1.636502</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.004888</td>\n",
              "      <td>1.154138</td>\n",
              "      <td>0.406961</td>\n",
              "      <td>0.061262</td>\n",
              "      <td>0.133552</td>\n",
              "      <td>0.178143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>(Comedy, Adventure)</td>\n",
              "      <td>(Action)</td>\n",
              "      <td>0.040970</td>\n",
              "      <td>0.283314</td>\n",
              "      <td>0.012568</td>\n",
              "      <td>0.306748</td>\n",
              "      <td>1.082714</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000960</td>\n",
              "      <td>1.033803</td>\n",
              "      <td>0.079658</td>\n",
              "      <td>0.040317</td>\n",
              "      <td>0.032698</td>\n",
              "      <td>0.175554</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>(Mystery)</td>\n",
              "      <td>(Thriller)</td>\n",
              "      <td>0.107453</td>\n",
              "      <td>0.211638</td>\n",
              "      <td>0.033220</td>\n",
              "      <td>0.309162</td>\n",
              "      <td>1.460808</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.010479</td>\n",
              "      <td>1.141168</td>\n",
              "      <td>0.353424</td>\n",
              "      <td>0.116208</td>\n",
              "      <td>0.123705</td>\n",
              "      <td>0.233065</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>(Mystery)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.107453</td>\n",
              "      <td>0.400276</td>\n",
              "      <td>0.044322</td>\n",
              "      <td>0.412476</td>\n",
              "      <td>1.030477</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.001311</td>\n",
              "      <td>1.020764</td>\n",
              "      <td>0.033136</td>\n",
              "      <td>0.095643</td>\n",
              "      <td>0.020341</td>\n",
              "      <td>0.261602</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>(Mystery)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.107453</td>\n",
              "      <td>0.207574</td>\n",
              "      <td>0.030581</td>\n",
              "      <td>0.284600</td>\n",
              "      <td>1.371079</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.008277</td>\n",
              "      <td>1.107669</td>\n",
              "      <td>0.303230</td>\n",
              "      <td>0.107511</td>\n",
              "      <td>0.097203</td>\n",
              "      <td>0.215963</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>(Mystery)</td>\n",
              "      <td>(Horror)</td>\n",
              "      <td>0.107453</td>\n",
              "      <td>0.178250</td>\n",
              "      <td>0.033555</td>\n",
              "      <td>0.312281</td>\n",
              "      <td>1.751928</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.014402</td>\n",
              "      <td>1.194892</td>\n",
              "      <td>0.480871</td>\n",
              "      <td>0.133079</td>\n",
              "      <td>0.163104</td>\n",
              "      <td>0.250265</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>(Mystery, Thriller)</td>\n",
              "      <td>(Horror)</td>\n",
              "      <td>0.033220</td>\n",
              "      <td>0.178250</td>\n",
              "      <td>0.012400</td>\n",
              "      <td>0.373266</td>\n",
              "      <td>2.094062</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.006478</td>\n",
              "      <td>1.311163</td>\n",
              "      <td>0.540412</td>\n",
              "      <td>0.062290</td>\n",
              "      <td>0.237318</td>\n",
              "      <td>0.221416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>(Mystery, Horror)</td>\n",
              "      <td>(Thriller)</td>\n",
              "      <td>0.033555</td>\n",
              "      <td>0.211638</td>\n",
              "      <td>0.012400</td>\n",
              "      <td>0.369538</td>\n",
              "      <td>1.746089</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.005298</td>\n",
              "      <td>1.250452</td>\n",
              "      <td>0.442127</td>\n",
              "      <td>0.053266</td>\n",
              "      <td>0.200289</td>\n",
              "      <td>0.214064</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>(Drama, Mystery)</td>\n",
              "      <td>(Crime)</td>\n",
              "      <td>0.044322</td>\n",
              "      <td>0.207574</td>\n",
              "      <td>0.013238</td>\n",
              "      <td>0.298677</td>\n",
              "      <td>1.438893</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.004038</td>\n",
              "      <td>1.129901</td>\n",
              "      <td>0.319167</td>\n",
              "      <td>0.055468</td>\n",
              "      <td>0.114967</td>\n",
              "      <td>0.181225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>(Mystery, Crime)</td>\n",
              "      <td>(Drama)</td>\n",
              "      <td>0.030581</td>\n",
              "      <td>0.400276</td>\n",
              "      <td>0.013238</td>\n",
              "      <td>0.432877</td>\n",
              "      <td>1.081444</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.000997</td>\n",
              "      <td>1.057483</td>\n",
              "      <td>0.077686</td>\n",
              "      <td>0.031698</td>\n",
              "      <td>0.054359</td>\n",
              "      <td>0.232974</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-27d7c3b2-047f-4a87-8bf3-e7e5661b12c7')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-27d7c3b2-047f-4a87-8bf3-e7e5661b12c7 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-27d7c3b2-047f-4a87-8bf3-e7e5661b12c7');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-7e64ac01-2e77-4ab4-b055-a47419db6d60\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-7e64ac01-2e77-4ab4-b055-a47419db6d60')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-7e64ac01-2e77-4ab4-b055-a47419db6d60 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_0f62e885-20c6-48bf-90b9-a07be7f0b2ae\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('high_confidence_rules')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_0f62e885-20c6-48bf-90b9-a07be7f0b2ae button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('high_confidence_rules');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "high_confidence_rules",
              "summary": "{\n  \"name\": \"high_confidence_rules\",\n  \"rows\": 38,\n  \"fields\": [\n    {\n      \"column\": \"antecedents\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 29,\n        \"samples\": [\n          \"frozenset({'Drama', 'Mystery'})\",\n          \"frozenset({'Animation', 'Adventure'})\",\n          \"frozenset({'Action', 'Thriller'})\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"consequents\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 8,\n        \"samples\": [\n          \"frozenset({'Comedy'})\",\n          \"frozenset({'Thriller'})\",\n          \"frozenset({'Adventure'})\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"antecedent support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08875022520585615,\n        \"min\": 0.01688240961836538,\n        \"max\": 0.4002764861128566,\n        \"num_unique_values\": 29,\n        \"samples\": [\n          0.04432156172761929,\n          0.028695907167693015,\n          0.043399941351430604\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"consequent support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.08577883739873504,\n        \"min\": 0.16367140044405346,\n        \"max\": 0.4002764861128566,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.19655649113987683,\n          0.21163755184114616,\n          0.1734321980645972\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"support\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.028552524159669298,\n        \"min\": 0.010054040467512881,\n        \"max\": 0.10762012483766914,\n        \"num_unique_values\": 28,\n        \"samples\": [\n          0.029617527543881698,\n          0.033555360060324245,\n          0.07352017091868794\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"confidence\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.12137642665538252,\n        \"min\": 0.2595002217950613,\n        \"max\": 0.6755852842809363,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          0.312280701754386,\n          0.29867674858223064,\n          0.3041825095057034\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"lift\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.5048674946768482,\n        \"min\": 1.0064268495037727,\n        \"max\": 3.634117308591362,\n        \"num_unique_values\": 37,\n        \"samples\": [\n          2.99899034916862,\n          1.0064268495037727,\n          1.0736567624442772\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"representativity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0,\n        \"min\": 1.0,\n        \"max\": 1.0,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"leverage\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.008903376322018841,\n        \"min\": 0.000189131870132659,\n        \"max\": 0.03041674184110968,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          0.0040378141527228194\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"conviction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.26574087903747995,\n        \"min\": 1.0043079836564281,\n        \"max\": 2.23561626966421,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          1.1948919318890054\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"zhangs_metric\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.17777729455829827,\n        \"min\": 0.00689255035107424,\n        \"max\": 0.7372770292668589,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          0.4808710317397537\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"jaccard\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06085075995632699,\n        \"min\": 0.031698264620323,\n        \"max\": 0.2151411104597605,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          0.05546779006494646\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"certainty\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.13194760142396353,\n        \"min\": 0.004289504540971489,\n        \"max\": 0.5526960446793491,\n        \"num_unique_values\": 38,\n        \"samples\": [\n          0.1631042328496609\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"kulczynski\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.07492590284756188,\n        \"min\": 0.16338942373251153,\n        \"max\": 0.3943249627625656,\n        \"num_unique_values\": 33,\n        \"samples\": [\n          0.18122535713672583\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Descriptions:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "0    Two teams try to entice unsuspecting people to...\n",
              "1    The coverage of the day's Remembrance Day cere...\n",
              "2    A DEA undercover agent who works for the bigge...\n",
              "3    Natural resources are running out and a myster...\n",
              "4    A North Korean romantic comedy that involves m...\n",
              "Name: description, dtype: object"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>description</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Two teams try to entice unsuspecting people to...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>The coverage of the day's Remembrance Day cere...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>A DEA undercover agent who works for the bigge...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Natural resources are running out and a myster...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>A North Korean romantic comedy that involves m...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> object</label>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Binary Labels (y):\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
              "        0, 0, 1, 0, 0],\n",
              "       [0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0,\n",
              "        0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1.1. Train+Val / Test Split and tokenizer and model loading\n",
        "\n",
        "This cell defines and trains a baseline multi-label classification model using a pre-trained DistilBERT model.\n",
        "\n",
        "- **Device Configuration:** Sets the device to \"cuda\" if a GPU is available, otherwise \"cpu\".\n",
        "- **Tokenizer and Model Loading:** Loads the \"distilbert-base-uncased\" tokenizer and model from the Hugging Face library."
      ],
      "metadata": {
        "id": "fKOU3VaxMoQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "\n",
        "# Setup\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# Tokenization\n",
        "X_tok = tokenizer(df['description'].tolist(), padding='max_length', truncation=True,\n",
        "                  max_length=128, return_tensors='pt', return_attention_mask=True)\n",
        "\n",
        "input_ids, attention_mask = X_tok['input_ids'], X_tok['attention_mask']\n",
        "\n",
        "# Split train+val/test\n",
        "X_train_val_ids, X_test_ids, y_train_val, y_test, X_train_val_mask, X_test_mask = train_test_split(\n",
        "    input_ids, y, attention_mask, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Further split train into train and val (10% val)\n",
        "X_train_ids, X_val_ids, y_train, y_val, X_train_mask, X_val_mask = train_test_split(\n",
        "    X_train_val_ids, y_train_val, X_train_val_mask, test_size=0.125, random_state=42\n",
        ")\n",
        "\n",
        "# Calculate and clamp pos_weight\n",
        "positive_counts = np.sum(y_train, axis=0)\n",
        "total_counts = y_train.shape[0]\n",
        "negative_counts = total_counts - positive_counts\n",
        "epsilon = 1e-5\n",
        "pos_weights_np = negative_counts / (positive_counts + epsilon)\n",
        "pos_weights_np = np.clip(pos_weights_np, 0.1, 10.0)\n",
        "pos_weights = torch.tensor(pos_weights_np, dtype=torch.float32).to(device)\n",
        "\n",
        "print(\"initial setup completed...\")"
      ],
      "metadata": {
        "id": "FoM0vprqMo5S",
        "outputId": "f0267875-7307-46e2-e3fd-6891b7a2bb66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initial setup completed...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8fffe5a"
      },
      "source": [
        "### 2. Baseline Model Training\n",
        "\n",
        "This cell defines and trains a baseline multi-label classification model using a pre-trained DistilBERT model.\n",
        "\n",
        "- **Model Definition:**\n",
        "    - A `BaselineMovieClassifier` class is defined, which includes the DistilBERT model and a linear classifier layer.\n",
        "    - The model takes tokenized input and produces logits for each genre.\n",
        "- **Training Setup:**\n",
        "    - The model, loss function (BCEWithLogitsLoss), and optimizer (Adam) are initialized.\n",
        "- **Data Preparation:**\n",
        "    - The movie descriptions are tokenized using the DistilBERT tokenizer.\n",
        "    - The data is split into training and testing sets.\n",
        "    - A DataLoader is created for the training data to handle batching and shuffling.\n",
        "- **Training Loop:**\n",
        "    - The model is trained for 10 epochs.\n",
        "    - In each epoch, the model processes batches of data, calculates the loss, and updates its weights."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "de410944",
        "outputId": "3306d5a9-7ef8-4c0a-da2b-a1ac8d2e6e4a"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "\n",
        "transformer = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
        "\n",
        "# Classifier model\n",
        "class BaselineMovieClassifier(nn.Module):\n",
        "    def __init__(self, transformer_model, num_labels, dropout=0.3):\n",
        "        super(BaselineMovieClassifier, self).__init__()\n",
        "        self.transformer = transformer_model # transformer parameters are also updated unless explicitly freezed...!\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.classifier = nn.Linear(transformer_model.config.hidden_size, num_labels)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask=None):\n",
        "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embeddings = outputs.last_hidden_state[:, 0, :]  # CLS token\n",
        "        x = self.dropout(embeddings)\n",
        "        logits = self.classifier(x)\n",
        "        return logits\n",
        "\n",
        "# Prepare data and labels (assumes mlb and df already defined)\n",
        "num_genres = len(mlb.classes_)\n",
        "baseline_model = BaselineMovieClassifier(transformer, num_genres).to(device)\n",
        "\n",
        "criterion = nn.BCEWithLogitsLoss(pos_weight=pos_weights)\n",
        "\n",
        "# Hyperparams\n",
        "epochs = 10\n",
        "batch_size = 32\n",
        "optimizer = optim.Adam(baseline_model.parameters(), lr=3e-5, weight_decay=0.01)\n",
        "total_steps = (len(X_train_ids) // batch_size + 1) * epochs\n",
        "warmup_steps = int(0.1 * total_steps)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, warmup_steps, total_steps)\n",
        "max_grad_norm = 1.0\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(\n",
        "    X_train_ids.to(device),\n",
        "    X_train_mask.to(device),\n",
        "    torch.tensor(y_train, dtype=torch.float32).to(device)\n",
        ")\n",
        "val_dataset = torch.utils.data.TensorDataset(\n",
        "    X_val_ids.to(device),\n",
        "    X_val_mask.to(device),\n",
        "    torch.tensor(y_val, dtype=torch.float32).to(device)\n",
        ")\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "def evaluate(model, loader):\n",
        "    model.eval()\n",
        "    losses = []\n",
        "    preds = []\n",
        "    targets = []\n",
        "    with torch.no_grad():\n",
        "        for batch_input_ids, batch_attention_mask, batch_y_true in loader:\n",
        "            logits = model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "            loss = criterion(logits, batch_y_true)\n",
        "            losses.append(loss.item())\n",
        "\n",
        "            y_pred = torch.sigmoid(logits).cpu().numpy()\n",
        "            preds.append(y_pred)\n",
        "            targets.append(batch_y_true.cpu().numpy())\n",
        "\n",
        "    avg_loss = np.mean(losses)\n",
        "    preds = np.vstack(preds)\n",
        "    targets = np.vstack(targets)\n",
        "    # Binarize preds with 0.5 threshold for metric\n",
        "    preds_binary = (preds > 0.5).astype(int)\n",
        "\n",
        "    f1 = f1_score(targets, preds_binary, average='micro', zero_division=0)\n",
        "    return avg_loss, f1\n",
        "\n",
        "# early-stopping\n",
        "best_val_f1 = 0.0\n",
        "patience = 4  # Number of epochs to wait before stopping\n",
        "epochs_without_improvement = 0\n",
        "best_model_state = None  # To store best model\n",
        "\n",
        "# Training loop with validation\n",
        "for epoch in range(epochs):\n",
        "    baseline_model.train()\n",
        "    total_loss = 0\n",
        "    for batch_input_ids, batch_attention_mask, batch_y_true in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        logits = baseline_model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        loss = criterion(logits, batch_y_true)\n",
        "\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(baseline_model.parameters(), max_grad_norm)\n",
        "\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    train_loss = total_loss / len(train_loader)\n",
        "    val_loss, val_f1 = evaluate(baseline_model, val_loader)\n",
        "    print(f\"Epoch {epoch+1}/{epochs} | Train Loss: {train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Micro F1: {val_f1:.4f}\")\n",
        "\n",
        "    # --- Early Stopping Logic ---\n",
        "    if val_f1 > best_val_f1:\n",
        "        best_val_f1 = val_f1\n",
        "        epochs_without_improvement = 0\n",
        "        best_model_state = baseline_model.state_dict()  # Save best model\n",
        "    else:\n",
        "        epochs_without_improvement += 1\n",
        "        if epochs_without_improvement >= patience:\n",
        "            print(f\"\\nEarly stopping triggered. Best Val F1: {best_val_f1:.4f}\")\n",
        "            break\n",
        "\n",
        "if best_model_state:\n",
        "    baseline_model.load_state_dict(best_model_state)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 | Train Loss: 0.7323 | Val Loss: 0.5842 | Val Micro F1: 0.4547\n",
            "Epoch 2/10 | Train Loss: 0.5539 | Val Loss: 0.5388 | Val Micro F1: 0.4450\n",
            "Epoch 3/10 | Train Loss: 0.5388 | Val Loss: 0.5357 | Val Micro F1: 0.4583\n",
            "Epoch 4/10 | Train Loss: 0.5348 | Val Loss: 0.5384 | Val Micro F1: 0.4765\n",
            "Epoch 5/10 | Train Loss: 0.5312 | Val Loss: 0.5350 | Val Micro F1: 0.4712\n",
            "Epoch 6/10 | Train Loss: 0.5276 | Val Loss: 0.5402 | Val Micro F1: 0.4559\n",
            "Epoch 7/10 | Train Loss: 0.5214 | Val Loss: 0.5360 | Val Micro F1: 0.4726\n",
            "Epoch 8/10 | Train Loss: 0.5162 | Val Loss: 0.5384 | Val Micro F1: 0.4718\n",
            "\n",
            "Early stopping triggered. Best Val F1: 0.4765\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "334bea93"
      },
      "source": [
        "### 3. Baseline Model Evaluation\n",
        "\n",
        "This cell evaluates the performance of the trained baseline model on the test set.\n",
        "\n",
        "- **Evaluation Mode:** The model is set to evaluation mode using `baseline_model.eval()`.\n",
        "- **Prediction:** The model makes predictions on the test data.\n",
        "- **Classification Report:** A classification report is printed, showing precision, recall, and F1-score for each genre."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "da93fe8d",
        "outputId": "02d79542-3e12-4b58-ae7c-a50a845e09e8"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "# Create test dataset with attention mask\n",
        "test_dataset = TensorDataset(\n",
        "    X_test_ids.to(device),\n",
        "    X_test_mask.to(device),\n",
        "    torch.tensor(y_test, dtype=torch.float32).to(device)\n",
        ")\n",
        "\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Evaluation\n",
        "baseline_model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_input_ids, batch_attention_mask, batch_y_true in test_loader:\n",
        "        # Pass attention mask to model\n",
        "        logits = baseline_model(batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        preds = (probs > 0.6).cpu().numpy()\n",
        "\n",
        "        all_preds.append(preds)\n",
        "        all_labels.append(batch_y_true.cpu().numpy())\n",
        "\n",
        "# Concatenate predictions and labels\n",
        "import numpy as np\n",
        "y_pred_binary = np.vstack(all_preds)\n",
        "y_true = np.vstack(all_labels)\n",
        "\n",
        "# Generate classification report\n",
        "print(classification_report(y_true, y_pred_binary, target_names=mlb.classes_, zero_division=0))\n",
        "print(\"Avg predicted labels per sample:\", y_pred_binary.sum(axis=1).mean())\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Action       0.57      0.51      0.54      1373\n",
            "       Adult       0.00      0.00      0.00         0\n",
            "   Adventure       0.47      0.50      0.48       858\n",
            "   Animation       0.34      0.52      0.41       276\n",
            "   Biography       0.26      0.56      0.35       179\n",
            "      Comedy       0.42      0.26      0.32       895\n",
            "       Crime       0.48      0.70      0.57       981\n",
            "       Drama       0.59      0.48      0.53      1894\n",
            "      Family       0.30      0.42      0.35       334\n",
            "     Fantasy       0.25      0.51      0.33       423\n",
            "   Film-Noir       0.00      0.00      0.00        42\n",
            "   Game-Show       0.00      0.00      0.00         0\n",
            "     History       0.31      0.48      0.38       208\n",
            "      Horror       0.49      0.75      0.59       864\n",
            "       Music       0.20      0.01      0.02        78\n",
            "     Musical       0.00      0.00      0.00        73\n",
            "     Mystery       0.22      0.67      0.33       523\n",
            "        News       0.00      0.00      0.00         5\n",
            "  Reality-TV       0.00      0.00      0.00         3\n",
            "     Romance       0.43      0.65      0.52       767\n",
            "      Sci-Fi       0.34      0.68      0.45       371\n",
            "       Short       0.00      0.00      0.00         0\n",
            "       Sport       0.55      0.16      0.24        76\n",
            "   Talk-Show       0.00      0.00      0.00         1\n",
            "    Thriller       0.35      0.65      0.46       974\n",
            "         War       0.42      0.53      0.47       163\n",
            "     Western       0.00      0.00      0.00        34\n",
            "\n",
            "   micro avg       0.41      0.54      0.47     11395\n",
            "   macro avg       0.26      0.34      0.27     11395\n",
            "weighted avg       0.44      0.54      0.47     11395\n",
            " samples avg       0.41      0.56      0.44     11395\n",
            "\n",
            "Avg predicted labels per sample: 3.142198952879581\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04dd683f"
      },
      "source": [
        "### 4. Baseline Model Prediction on Evaluation Set\n",
        "\n",
        "This cell uses the trained baseline model to make predictions on a separate evaluation dataset.\n",
        "\n",
        "- **Load Evaluation Data:** Loads the evaluation dataset from a CSV file.\n",
        "- **Preprocess Evaluation Data:** The descriptions from the evaluation data are tokenized.\n",
        "- **Make Predictions:** The model predicts genres for the evaluation data.\n",
        "- **Store Predictions:** The predicted genres are added as a new column to the evaluation DataFrame.\n",
        "- **Classification Report:** A classification report is generated to evaluate the model's performance on this new data."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "13fcf9a0",
        "outputId": "e7bafe02-42ec-48fc-d21f-b4a7f6988d05"
      },
      "source": [
        "# Load the evaluation data\n",
        "eval_df = pd.read_csv('/content/drive/My Drive/movie-genre-prediction/test.csv')\n",
        "\n",
        "# Preprocess the evaluation data\n",
        "eval_descriptions = eval_df['description'].tolist()\n",
        "eval_X = tokenizer(\n",
        "    text=eval_descriptions,\n",
        "    add_special_tokens=True,\n",
        "    max_length=128,\n",
        "    truncation=True,\n",
        "    padding='max_length',\n",
        "    return_tensors='pt',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = True,\n",
        "    verbose = True)\n",
        "\n",
        "# Move data to device\n",
        "eval_input_ids = eval_X['input_ids']\n",
        "eval_attention_mask = eval_X['attention_mask']\n",
        "\n",
        "# Create dataset and loader\n",
        "eval_dataset = TensorDataset(eval_input_ids, eval_attention_mask)\n",
        "eval_loader = DataLoader(eval_dataset, batch_size=32)  # use smaller batch_size if needed\n",
        "\n",
        "# Predict in batches\n",
        "baseline_model.eval()\n",
        "all_preds = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_ids, batch_mask in eval_loader:\n",
        "        batch_ids = batch_ids.to(device)\n",
        "        batch_mask = batch_mask.to(device)\n",
        "\n",
        "        logits = baseline_model(batch_ids, attention_mask=batch_mask)\n",
        "        probs = torch.sigmoid(logits)\n",
        "        batch_preds = (probs > 0.5).cpu().numpy()\n",
        "        all_preds.append(batch_preds)\n",
        "\n",
        "# Final predictions\n",
        "import numpy as np\n",
        "predicted_labels_binary = np.vstack(all_preds)\n",
        "\n",
        "# Convert binary predictions to genre labels\n",
        "predicted_labels = mlb.inverse_transform(predicted_labels_binary)\n",
        "\n",
        "# Attach predictions to dataframe\n",
        "eval_df['predicted_genres_baseline'] = predicted_labels\n",
        "\n",
        "# Get true labels from CSV\n",
        "y_true_eval = mlb.transform(eval_df['expanded-genres'].str.split(', '))\n",
        "\n",
        "# Print classification report\n",
        "print(\"Classification Report for baseline model on the evaluation set:\")\n",
        "print(classification_report(y_true_eval, predicted_labels_binary, target_names=mlb.classes_, zero_division=0))\n",
        "\n",
        "# Optional: View predictions\n",
        "display(eval_df.head())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report for baseline model on the evaluation set:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Action       0.51      0.71      0.59      8550\n",
            "       Adult       0.00      0.00      0.00         2\n",
            "   Adventure       0.40      0.62      0.48      5112\n",
            "   Animation       0.28      0.57      0.37      1591\n",
            "   Biography       0.21      0.67      0.32      1117\n",
            "      Comedy       0.38      0.48      0.42      5738\n",
            "       Crime       0.39      0.81      0.53      6069\n",
            "       Drama       0.53      0.73      0.61     11998\n",
            "      Family       0.27      0.58      0.36      2102\n",
            "     Fantasy       0.21      0.63      0.32      2603\n",
            "   Film-Noir       0.00      0.00      0.00       237\n",
            "   Game-Show       0.00      0.00      0.00         1\n",
            "     History       0.29      0.63      0.39      1255\n",
            "      Horror       0.40      0.83      0.54      5159\n",
            "       Music       0.26      0.05      0.08       452\n",
            "     Musical       0.15      0.02      0.03       407\n",
            "     Mystery       0.19      0.78      0.31      3233\n",
            "        News       0.00      0.00      0.00         1\n",
            "  Reality-TV       0.00      0.00      0.00         4\n",
            "     Romance       0.37      0.76      0.50      5022\n",
            "      Sci-Fi       0.25      0.74      0.37      2172\n",
            "       Short       0.00      0.00      0.00         0\n",
            "       Sport       0.56      0.30      0.39       482\n",
            "   Talk-Show       0.00      0.00      0.00         1\n",
            "    Thriller       0.32      0.80      0.46      6196\n",
            "         War       0.34      0.66      0.45       916\n",
            "     Western       0.00      0.00      0.00       214\n",
            "\n",
            "   micro avg       0.36      0.69      0.47     70634\n",
            "   macro avg       0.23      0.42      0.28     70634\n",
            "weighted avg       0.38      0.69      0.48     70634\n",
            " samples avg       0.37      0.71      0.46     70634\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "                  movie title - year      genre             expanded-genres  \\\n",
              "0              Son of the Wolf - nan  Adventure                   Adventure   \n",
              "1                   Firstborn - 2003     Action  Action, Adventure, Fantasy   \n",
              "2                  13 Cameras - 2015   Thriller        Crime, Drama, Horror   \n",
              "3  Straight Up, Now Tell Me... - nan    Romance                     Romance   \n",
              "4           The Ugly Duckling - 1959      Crime       Comedy, Crime, Sci-Fi   \n",
              "\n",
              "   rating                                        description  \\\n",
              "0     NaN  Set in 1800'2 Yukon, The Malamute Kid takes on...   \n",
              "1     6.1  Sorcerers fight against themselves for ultimat...   \n",
              "2     5.2  A newlywed couple, move into a new house acros...   \n",
              "3     NaN  When a gay man brings his fiancee home to meet...   \n",
              "4     5.5  Henry Jeckle was always the outsider, a bungli...   \n",
              "\n",
              "                           predicted_genres_baseline  \n",
              "0                         (Action, Adventure, Crime)  \n",
              "1    (Action, Adventure, Animation, Fantasy, Sci-Fi)  \n",
              "2       (Comedy, Horror, Mystery, Romance, Thriller)  \n",
              "3  (Comedy, Crime, Drama, Mystery, Romance, Thril...  \n",
              "4                                   (Drama, Romance)  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-71105347-398a-4914-9c70-83107005f8b4\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>movie title - year</th>\n",
              "      <th>genre</th>\n",
              "      <th>expanded-genres</th>\n",
              "      <th>rating</th>\n",
              "      <th>description</th>\n",
              "      <th>predicted_genres_baseline</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Son of the Wolf - nan</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>Adventure</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Set in 1800'2 Yukon, The Malamute Kid takes on...</td>\n",
              "      <td>(Action, Adventure, Crime)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Firstborn - 2003</td>\n",
              "      <td>Action</td>\n",
              "      <td>Action, Adventure, Fantasy</td>\n",
              "      <td>6.1</td>\n",
              "      <td>Sorcerers fight against themselves for ultimat...</td>\n",
              "      <td>(Action, Adventure, Animation, Fantasy, Sci-Fi)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>13 Cameras - 2015</td>\n",
              "      <td>Thriller</td>\n",
              "      <td>Crime, Drama, Horror</td>\n",
              "      <td>5.2</td>\n",
              "      <td>A newlywed couple, move into a new house acros...</td>\n",
              "      <td>(Comedy, Horror, Mystery, Romance, Thriller)</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Straight Up, Now Tell Me... - nan</td>\n",
              "      <td>Romance</td>\n",
              "      <td>Romance</td>\n",
              "      <td>NaN</td>\n",
              "      <td>When a gay man brings his fiancee home to meet...</td>\n",
              "      <td>(Comedy, Crime, Drama, Mystery, Romance, Thril...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Ugly Duckling - 1959</td>\n",
              "      <td>Crime</td>\n",
              "      <td>Comedy, Crime, Sci-Fi</td>\n",
              "      <td>5.5</td>\n",
              "      <td>Henry Jeckle was always the outsider, a bungli...</td>\n",
              "      <td>(Drama, Romance)</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-71105347-398a-4914-9c70-83107005f8b4')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-71105347-398a-4914-9c70-83107005f8b4 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-71105347-398a-4914-9c70-83107005f8b4');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-dac52f5d-a750-410f-91b5-3cec8858ef11\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-dac52f5d-a750-410f-91b5-3cec8858ef11')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-dac52f5d-a750-410f-91b5-3cec8858ef11 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display(eval_df\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"movie title - year\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Firstborn - 2003\",\n          \"The Ugly Duckling - 1959\",\n          \"13 Cameras - 2015\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"genre\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Action\",\n          \"Crime\",\n          \"Thriller\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"expanded-genres\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Action, Adventure, Fantasy\",\n          \"Comedy, Crime, Sci-Fi\",\n          \"Crime, Drama, Horror\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"rating\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.4582575694955837,\n        \"min\": 5.2,\n        \"max\": 6.1,\n        \"num_unique_values\": 3,\n        \"samples\": [\n          6.1,\n          5.2,\n          5.5\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"description\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"Sorcerers fight against themselves for ultimate power and domination of the mortals of earth as the most powerful of them all, a boy, fights for his life, the life of his mother and the people of his village.\",\n          \"Henry Jeckle was always the outsider, a bungling and awkward buffoon, relegated to waiting for his invitation to participate in life that never arrived: until he discovers a medical formula...                See full summary\\u00a0\\u00bb\",\n          \"A newlywed couple, move into a new house across the country, only to find out that their marital issues are the least of their problems. Unbeknownst to them, their grim and lascivious landlord has been spying on them from day one.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"predicted_genres_baseline\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          [\n            \"Action\",\n            \"Adventure\",\n            \"Animation\",\n            \"Fantasy\",\n            \"Sci-Fi\"\n          ],\n          [\n            \"Drama\",\n            \"Romance\"\n          ],\n          [\n            \"Comedy\",\n            \"Horror\",\n            \"Mystery\",\n            \"Romance\",\n            \"Thriller\"\n          ]\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "840aa1c6"
      },
      "source": [
        "### 5. LTN Model Definition\n",
        "\n",
        "This cell defines the LTN-enhanced movie classifier.\n",
        "\n",
        "- **Model Definition:**\n",
        "    - An `LTNMovieClassifier` class is defined, which, like the baseline, uses a DistilBERT model for embeddings.\n",
        "    - Instead of a single classifier, it uses a dictionary of `ltn.Predicate` modules, one for each genre. Each predicate is a small neural network that learns a truth value for a movie belonging to a genre.\n",
        "- **Model Instantiation:** The LTN model is instantiated."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(dir(ltn.fuzzy_ops))"
      ],
      "metadata": {
        "id": "F0XysnVrsN7x",
        "outputId": "eeefde45-64ee-4672-b3a2-d2cc2bb3cec6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['AggregMean', 'AggregMin', 'AggregPMean', 'AggregPMeanError', 'AggregationOperator', 'AndLuk', 'AndMin', 'AndProd', 'BinaryConnectiveOperator', 'ConnectiveOperator', 'Equiv', 'ImpliesGodel', 'ImpliesGoguen', 'ImpliesKleeneDienes', 'ImpliesLuk', 'ImpliesReichenbach', 'LTNObject', 'NotGodel', 'NotStandard', 'OrLuk', 'OrMax', 'OrProbSum', 'SatAgg', 'UnaryConnectiveOperator', '__builtins__', '__cached__', '__doc__', '__file__', '__loader__', '__name__', '__package__', '__spec__', 'check_mask', 'check_values', 'eps', 'pi_0', 'pi_1', 'torch']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 188,
          "referenced_widgets": [
            "a7ac28948fff4f13bc12317829521c0b",
            "9a37fcc739534ffca31cd7fef7c8f87d",
            "28ccc756df24410e95cbc85d5842dd2a",
            "2d1476c0c19b4728b9d876446c0e67ff",
            "25100dda4c264b22aed4c453924790c7",
            "8f48e8f3d3f142c084172ee12bcc6d67",
            "fad27b1d83cc4488b5b181087a71bd08",
            "c754333daa534e328f73542ba6742753",
            "a07bd3ae5ade4833ab2fef0ba3e31e1c",
            "38e3d6b92f5a4fae9c029599fb7905bc",
            "501181774d6749549479f44340bf37d3"
          ]
        },
        "id": "39fb29b4",
        "outputId": "d349a130-fff2-4896-fdb8-b2e3c4aabcef"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score\n",
        "import ltn  # ltntorch for fuzzy logic\n",
        "from ltn.fuzzy_ops import Equiv, AndLuk, ImpliesLuk, AggregPMean\n",
        "\n",
        "# Label setup\n",
        "ALL_LABELS = list(mlb.classes_)\n",
        "NUM_LABELS = len(ALL_LABELS)\n",
        "LABEL_TO_IDX = {label: i for i, label in enumerate(ALL_LABELS)}\n",
        "\n",
        "# Fuzzy logic operators\n",
        "and_op = AndLuk()\n",
        "imp_op = ImpliesLuk()\n",
        "equiv_op = Equiv(and_op=and_op, implies_op=imp_op)\n",
        "aggregator = AggregPMean(p=2)\n",
        "\n",
        "# Build implication rules\n",
        "implication_pairs = []\n",
        "for _, row in high_confidence_rules.iterrows():\n",
        "    for a in list(row['antecedents']):\n",
        "        for c in list(row['consequents']):\n",
        "            if a in LABEL_TO_IDX and c in LABEL_TO_IDX:\n",
        "                implication_pairs.append((LABEL_TO_IDX[a], LABEL_TO_IDX[c]))\n",
        "implication_pairs = list(set(implication_pairs))\n",
        "print(f\"Loaded {len(implication_pairs)} implication rules from assoc rules.\")\n",
        "\n",
        "# LTN model definition\n",
        "class LTNMultiLabelClassifier(nn.Module):\n",
        "    def __init__(self, transformer_model, num_labels, implication_pairs, pos_weights=None):\n",
        "        super().__init__()\n",
        "        self.transformer = transformer_model # transformer parameters are also updated unless explicitly freezed...!\n",
        "        self.dropout = nn.Dropout(0.3)\n",
        "        self.fc = nn.Linear(transformer_model.config.hidden_size, num_labels)\n",
        "        self.implication_pairs = implication_pairs\n",
        "        self.pos_weights = pos_weights\n",
        "        self.loss_fn = nn.BCEWithLogitsLoss(pos_weight=self.pos_weights)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.transformer(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        embeddings = self.dropout(outputs.last_hidden_state[:, 0, :])\n",
        "        logits = self.fc(embeddings)\n",
        "        return logits  # raw logits, no sigmoid\n",
        "\n",
        "    def compute_loss(self, logits, true_labels):\n",
        "        pred_probs = torch.sigmoid(logits)\n",
        "        bce_loss = self.loss_fn(logits, true_labels)\n",
        "\n",
        "        equiv_values = equiv_op(pred_probs, true_labels)\n",
        "        sat_gt = aggregator(aggregator(equiv_values))\n",
        "\n",
        "        axiom_values = [imp_op(pred_probs[:, a], pred_probs[:, c]) for a, c in self.implication_pairs]\n",
        "        if axiom_values:\n",
        "            sat_axiom = aggregator(aggregator(torch.stack(axiom_values, dim=1)))\n",
        "        else:\n",
        "            sat_axiom = torch.tensor(1.0, device=logits.device)\n",
        "\n",
        "        logic_loss = 1 - and_op(sat_gt, sat_axiom)\n",
        "        total_loss = 0.95 * bce_loss + 0.05 * logic_loss\n",
        "        return total_loss, sat_gt.item(), sat_axiom.item()\n",
        "\n",
        "transformer = AutoModel.from_pretrained(\"distilbert-base-uncased\").to(device)\n",
        "\n",
        "# DataLoaders\n",
        "train_dataset = torch.utils.data.TensorDataset(\n",
        "    X_train_ids.to(device), X_train_mask.to(device), torch.tensor(y_train, dtype=torch.float32).to(device))\n",
        "val_dataset = torch.utils.data.TensorDataset(\n",
        "    X_val_ids.to(device), X_val_mask.to(device), torch.tensor(y_val, dtype=torch.float32).to(device))\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=32)\n",
        "\n",
        "model = LTNMultiLabelClassifier(transformer, NUM_LABELS, implication_pairs, pos_weights=pos_weights).to(device)\n",
        "\n",
        "# Optimizer\n",
        "optimizer = optim.Adam(model.parameters(), lr=3e-5, weight_decay=0.01)\n",
        "total_steps = len(train_loader) * 10\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, int(0.1 * total_steps), total_steps)\n",
        "\n",
        "# Training with early stopping\n",
        "best_val_f1 = 0.0\n",
        "patience = 4\n",
        "patience_counter = 0\n",
        "best_model_state = None\n",
        "\n",
        "for epoch in range(10):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    for batch_ids, batch_mask, batch_labels in train_loader:\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(batch_ids, batch_mask)\n",
        "        loss, sat_gt, sat_axiom = model.compute_loss(logits, batch_labels)\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_loader)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_preds, val_labels = [], []\n",
        "    val_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for batch_ids, batch_mask, batch_labels in val_loader:\n",
        "            logits = model(batch_ids, batch_mask)\n",
        "            loss, _, _ = model.compute_loss(logits, batch_labels)\n",
        "            val_loss += loss.item()\n",
        "            probs = torch.sigmoid(logits)  # apply sigmoid at eval time\n",
        "            val_preds.append(probs.cpu().numpy())\n",
        "            val_labels.append(batch_labels.cpu().numpy())\n",
        "\n",
        "    val_loss /= len(val_loader)\n",
        "    y_pred = np.vstack(val_preds)\n",
        "    y_true = np.vstack(val_labels)\n",
        "    y_pred_binary = (y_pred > 0.5).astype(int)\n",
        "    val_f1_micro = f1_score(y_true, y_pred_binary, average='micro', zero_division=0)\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/10 - Train Loss: {avg_train_loss:.4f} | Val Loss: {val_loss:.4f} | Val Micro F1: {val_f1_micro:.4f} | GT Sat: {sat_gt:.4f} | Axiom Sat: {sat_axiom:.4f}\")\n",
        "\n",
        "    if val_f1_micro > best_val_f1:\n",
        "        best_val_f1 = val_f1_micro\n",
        "        best_model_state = model.state_dict()\n",
        "        patience_counter = 0\n",
        "    else:\n",
        "        patience_counter += 1\n",
        "        if patience_counter >= patience:\n",
        "            print(f\"Early stopping at epoch {epoch+1}\")\n",
        "            break\n",
        "\n",
        "if best_model_state:\n",
        "    model.load_state_dict(best_model_state)\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 30 implication rules from assoc rules.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "a7ac28948fff4f13bc12317829521c0b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10 - Train Loss: 0.7118 | Val Loss: 0.5607 | Val Micro F1: 0.4340 | GT Sat: 0.7707 | Axiom Sat: 0.9376\n",
            "Epoch 2/10 - Train Loss: 0.5395 | Val Loss: 0.5302 | Val Micro F1: 0.4813 | GT Sat: 0.8029 | Axiom Sat: 0.9405\n",
            "Epoch 3/10 - Train Loss: 0.5234 | Val Loss: 0.5277 | Val Micro F1: 0.4502 | GT Sat: 0.7861 | Axiom Sat: 0.9324\n",
            "Epoch 4/10 - Train Loss: 0.5228 | Val Loss: 0.5280 | Val Micro F1: 0.4797 | GT Sat: 0.8231 | Axiom Sat: 0.9550\n",
            "Epoch 5/10 - Train Loss: 0.5216 | Val Loss: 0.5436 | Val Micro F1: 0.4706 | GT Sat: 0.8208 | Axiom Sat: 0.9472\n",
            "Epoch 6/10 - Train Loss: 0.5171 | Val Loss: 0.5390 | Val Micro F1: 0.4397 | GT Sat: 0.7864 | Axiom Sat: 0.9477\n",
            "Early stopping at epoch 6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. LTN Model Evaluation\n",
        "\n",
        "This cell evaluates the performance of the trained LTN model on the test set.\n",
        "\n",
        "- **Evaluation Mode:** The model is set to evaluation mode using `model.eval()`.\n",
        "- **Prediction:** The model makes predictions on the test data.\n",
        "- **Classification Report:** A classification report is printed, showing precision, recall, and F1-score for each genre."
      ],
      "metadata": {
        "id": "FlEN36-LyCxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from ltn.fuzzy_ops import ImpliesLuk, AggregPMean\n",
        "import torch\n",
        "import numpy as np\n",
        "\n",
        "# Prepare axiom operators\n",
        "imp_op = ImpliesLuk()\n",
        "aggregator = AggregPMean(p=2)\n",
        "\n",
        "# Test DataLoader with attention_mask\n",
        "test_dataset = TensorDataset(\n",
        "    X_test_ids.to(device),\n",
        "    X_test_mask.to(device),\n",
        "    torch.tensor(y_test, dtype=torch.float32).to(device)\n",
        ")\n",
        "test_loader = DataLoader(test_dataset, batch_size=32)\n",
        "\n",
        "# Switch to eval mode\n",
        "model.eval()\n",
        "all_preds = []\n",
        "all_labels = []\n",
        "all_axioms = []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for batch_input_ids, batch_attention_mask, batch_y_true in test_loader:\n",
        "        # Forward pass\n",
        "        logits = model(input_ids=batch_input_ids, attention_mask=batch_attention_mask)\n",
        "        probs = torch.sigmoid(logits)\n",
        "\n",
        "        # Binary predictions\n",
        "        preds = (probs > 0.5).cpu().numpy()\n",
        "        all_preds.append(preds)\n",
        "        all_labels.append(batch_y_true.cpu().numpy())\n",
        "\n",
        "        # Axiom satisfaction\n",
        "        if hasattr(model, \"implication_pairs\"):\n",
        "            axiom_vals = []\n",
        "            for a_idx, c_idx in model.implication_pairs:\n",
        "                premise = probs[:, a_idx]\n",
        "                conclusion = probs[:, c_idx]\n",
        "                val = imp_op(premise, conclusion)\n",
        "                axiom_vals.append(val)\n",
        "            if axiom_vals:\n",
        "                stacked_axioms = torch.stack(axiom_vals, dim=1)\n",
        "                sat_per_example = aggregator(stacked_axioms)\n",
        "                all_axioms.append(sat_per_example.cpu().numpy())\n",
        "\n",
        "# Concatenate results\n",
        "y_pred_binary = np.vstack(all_preds)\n",
        "y_true = np.vstack(all_labels)\n",
        "\n",
        "# Classification report\n",
        "print(\"\\nMulti-label classification report:\")\n",
        "print(classification_report(y_true, y_pred_binary, target_names=mlb.classes_, zero_division=0))\n",
        "\n",
        "# Axiom satisfaction report\n",
        "if all_axioms:\n",
        "    axiom_scores = np.stack(all_axioms)\n",
        "    print(f\"\\nAverage axiom satisfaction on test set: {axiom_scores.mean():.4f}\")\n",
        "    print(f\"Min: {axiom_scores.min():.4f}, Max: {axiom_scores.max():.4f}\")\n",
        "else:\n",
        "    print(\"\\nNo implication rules found in model for axiom satisfaction.\")\n",
        "\n",
        "print(\"\\nAvg predicted labels per sample:\", y_pred_binary.sum(axis=1).mean())\n"
      ],
      "metadata": {
        "id": "S1Dql6eNyEMk",
        "outputId": "f14f1039-e17e-4fef-d82a-790a592c642a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Multi-label classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "      Action       0.46      0.77      0.58      1373\n",
            "       Adult       0.00      0.00      0.00         0\n",
            "   Adventure       0.31      0.81      0.45       858\n",
            "   Animation       0.26      0.72      0.38       276\n",
            "   Biography       0.33      0.37      0.35       179\n",
            "      Comedy       0.37      0.37      0.37       895\n",
            "       Crime       0.44      0.75      0.56       981\n",
            "       Drama       0.58      0.50      0.53      1894\n",
            "      Family       0.26      0.50      0.34       334\n",
            "     Fantasy       0.20      0.74      0.31       423\n",
            "   Film-Noir       0.00      0.00      0.00        42\n",
            "   Game-Show       0.00      0.00      0.00         0\n",
            "     History       0.33      0.47      0.39       208\n",
            "      Horror       0.33      0.92      0.49       864\n",
            "       Music       0.25      0.01      0.02        78\n",
            "     Musical       0.00      0.00      0.00        73\n",
            "     Mystery       0.19      0.82      0.30       523\n",
            "        News       0.00      0.00      0.00         5\n",
            "  Reality-TV       0.00      0.00      0.00         3\n",
            "     Romance       0.49      0.56      0.52       767\n",
            "      Sci-Fi       0.18      0.89      0.30       371\n",
            "       Short       0.00      0.00      0.00         0\n",
            "       Sport       0.70      0.18      0.29        76\n",
            "   Talk-Show       0.00      0.00      0.00         1\n",
            "    Thriller       0.30      0.81      0.44       974\n",
            "         War       0.38      0.57      0.45       163\n",
            "     Western       0.00      0.00      0.00        34\n",
            "\n",
            "   micro avg       0.33      0.66      0.44     11395\n",
            "   macro avg       0.24      0.40      0.26     11395\n",
            "weighted avg       0.38      0.66      0.45     11395\n",
            " samples avg       0.34      0.68      0.43     11395\n",
            "\n",
            "\n",
            "Average axiom satisfaction on test set: 0.9426\n",
            "Min: 0.9307, Max: 0.9541\n",
            "\n",
            "Avg predicted labels per sample: 4.721256544502618\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bf79f81"
      },
      "source": [
        "### 7. Model Performance Comparison\n",
        "\n",
        "LTN encouraged the model to satisfy logical constraints, which in multi-label classification often boosts recall at the cost of precision.\n",
        "\n",
        "For example: If the rules say “Sci-Fi often co-occurs with Thriller”, the model will predict Thriller more often, even when unsure — hence more recall, less precision.\n",
        "\n",
        "Next step is threshold calibration — because with LTN, the “predict more” approach is overshooting."
      ]
    }
  ]
}